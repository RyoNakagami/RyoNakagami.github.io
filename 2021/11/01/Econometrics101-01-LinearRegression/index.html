<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="gSMaswRY9iRfG4QaQrx6aj481bgr503qEZh-QPsMYNU" />
    <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
    <meta name="description" content="元経済学徒, 現在どっかでデータサイエンティストもどきやってる人間の勉強日記">
    <meta name="keywords"  content="Statistics, Economics, Econometrics, Python, C, Shell, Linux, Data scientist">
    <meta name="theme-color" content="#000000">
    
    <!-- Open Graph -->
    <meta property="og:title" content="Econometrics101 - 復習 - Ryo's Tech Blog">
    
    <meta property="og:type" content="article">
    <meta property="og:description" content="
  
    
       
      概要
    
  
  
    
      目的
      Linear Regression: OLS finite sample and larger sample property
    
    
      参考
      - PennState STAT 501
    
    
      関連記事
       
 ...">
    
    <meta property="article:published_time" content="2021-11-01T00:00:00Z">
    
    
    <meta property="article:author" content="Ryo">
    
    
    <meta property="article:tag" content="Econometrics">
    
    
    <meta property="og:image" content="https://ryonakagami.github.io/img/avatar_rio_cat.jpg">
    <meta property="og:url" content="https://ryonakagami.github.io/2021/11/01/Econometrics101-01-LinearRegression/">
    <meta property="og:site_name" content="Ryo's Tech Blog">
    
    <title>Econometrics101 - 復習 - Ryo's Tech Blog</title>

    <!-- Web App Manifest -->
    <link rel="manifest" href="/pwa/manifest.json">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/img/favicon.ico">
    
    <!-- Canonical URL -->
    <link rel="canonical" href="https://ryonakagami.github.io/2021/11/01/Econometrics101-01-LinearRegression/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/ryo-blog.min.css">

    <!-- Custom Fonts -->
    <!-- <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- https://stackoverflow.com/questions/45983301/google-pagespeed-eliminate-render-blocking-resources-above-the-fold-caused-fro -->
    <!--link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"-->
    <!--<link href="https://fonts.googleapis.com/earlyaccess/notosansjapanese.css" rel="stylesheet" type="text/css" media="print" onload="this.media='all'" > -->
    <link href="https://fonts.googleapis.com/earlyaccess/notosansjapanese.css" rel="preload" type="text/css" media="print" onload="this.media='all'" >


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- Navigation -->

<nav class="navbar navbar-default navbar-custom navbar-fixed-top invert">
    
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="/">Ryo's Tech Blog</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div id="huxblog_navbar">
                <div class="navbar-collapse">
                    <ul class="nav navbar-nav navbar-left">
                                                <li>
                            <a href="https://ryonakagami.github.io/statistics-for-regression-monkey/">Statistics for
                                Regression Monkeys</a>
                        </li>
                        <li>
                            <a href="https://ohgoshgit.github.io/">OhGoshGit!?!</a>
                        </li>
                        <!-- <li>
                            <a><button onclick="mainDropDown()" style="border-color: rgba(70, 83, 111, 0.989); background-color: rgba(70, 83, 111, 0.989)">Dropdown</button></a> 
                            <div id="myDropdown" class="dropdown-content">
                              <a href="#" onclick="subMenu(this)">A</a>
                              <div class="sub-menu-item" id="subMenu1">
                              <a href="#">A.1</a>
                              </div>
                              <a href="#" onclick="subMenu(this)">B</a>
                              <div class="sub-menu-item" id="subMenu2">
                              <a href="#">B.1</a>
                              </div>
                              <a href="#">C</a>
                              <a href="#">D</a>
                              <a href="#">E</a>
                              <a href="#">F</a>
                              <a href="#">G</a>
                            </div>
                        </li> -->
                    </ul>
                    </ul>
                    <ul class="nav navbar-nav navbar-right">
                        
                        
                        
                        
                        <li>
                            <a href="/about/">About</a>
                        </li>
                        
                        
                        
                        <li>
                            <a href="/archive/">Tag Search</a>
                        </li>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <!--about fa-search see https://stackoverflow.com/questions/41950677/how-to-make-my-search-icon-fixed-->
                        <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css"
                            rel="stylesheet" />
                        <li class="search-icon">
                            <a href="javascript:void(0)" aria-label="Search" target="_blank">
                                <i class="fa fa-search"></i>
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <script>
        // Drop Bootstarp low-performance Navbar
        // Use customize navbar with high-quality material design animation
        // in high-perf jank-free CSS3 implementation
        var $body = document.body;
        var $toggle = document.querySelector('.navbar-toggle');
        var $navbar = document.querySelector('#huxblog_navbar');
        var $collapse = document.querySelector('.navbar-collapse');

        var __HuxNav__ = {
            close: function () {
                $navbar.className = " ";
                // wait until animation end.
                setTimeout(function () {
                    // prevent frequently toggle
                    if ($navbar.className.indexOf('in') < 0) {
                        $collapse.style.height = "0px"
                    }
                }, 400)
            },
            open: function () {
                $collapse.style.height = "auto"
                $navbar.className += " in";
            }
        }

        // Bind Event
        $toggle.addEventListener('click', function (e) {
            if ($navbar.className.indexOf('in') > 0) {
                __HuxNav__.close()
            } else {
                __HuxNav__.open()
            }
        })

        /**
         * Since Fastclick is used to delegate 'touchstart' globally
         * to hack 300ms delay in iOS by performing a fake 'click',
         * Using 'e.stopPropagation' to stop 'touchstart' event from 
         * $toggle/$collapse will break global delegation.
         * 
         * Instead, we use a 'e.target' filter to prevent handler
         * added to document close HuxNav.  
         *
         * Also, we use 'click' instead of 'touchstart' as compromise
         */
        document.addEventListener('click', function (e) {
            if (e.target == $toggle) return;
            if (e.target.className == 'icon-bar') return;
            __HuxNav__.close();
        })
    </script>

    <!-- Search -->
<div class="search-page">
  <div class="search-icon-close-container">
    <span class="search-icon-close">
      <i class="fa fa-chevron-down"></i>
    </span>
  </div>
  <div class="search-main container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <form></form>
        <input type="text" id="search-input" placeholder="$ grep...">
        </form>
        <div id="search-results" class="mini-post-list"></div>
      </div>
    </div>
  </div>
</div>


    <!-- Image to hack wechat -->
<!-- <img src="/img/icon_wechat.png" width="0" height="0"> -->
<!-- <img src="/img/home-bg.jpg" width="0" height="0"> -->

<!-- Post Header -->



<style type="text/css">
    header.intro-header{
        position: relative;
        background-image: url('/img/home-bg.jpg');
        background: ;
    }

    
    header.intro-header .header-mask{
        width: 100%;
        height: 100%;
        position: absolute;
        background: rgba(0,0,0, 0.0);
    }
    
</style>




<header class="intro-header style-text" >

    <div class="header-mask"></div>
    
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/archive/?tag=Econometrics" title="Econometrics">Econometrics</a>
                        
                    </div>
                    <h1>Econometrics101 - 復習</h1>
                    
                    <h2 class="subheading">Linear Regression: OLS finite sample and larger sample property</h2>
                    <p>
                        公開日: 2021-11-01
                        
                        
                    </p>
                </div>
            </div>
        </div>
    </div>
</header>







<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
         <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <!-- Multi-Lingual -->
                

				<table>
  <thead>
    <tr>
      <th> </th>
      <th>概要</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>目的</td>
      <td>Linear Regression: OLS finite sample and larger sample property</td>
    </tr>
    <tr>
      <td>参考</td>
      <td>- <a href="https://online.stat.psu.edu/stat501/lesson/11/11.2">PennState STAT 501</a></td>
    </tr>
    <tr>
      <td>関連記事</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<p><strong>Table of Contents</strong>
<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE --></p>

<ul>
  <li><a href="#1-linear-regression%E3%81%AE%E8%A7%A3%E9%87%88">1. Linear Regressionの解釈</a>
    <ul>
      <li><a href="#%E8%A7%A3%E9%87%88-1-linear-conditional-expectations">解釈 1: Linear Conditional Expectations</a></li>
      <li><a href="#%E8%A7%A3%E9%87%88-2-the-cef%E3%81%AEbest%E7%B7%9A%E5%BD%A2%E8%BF%91%E4%BC%BC">解釈 2: The CEFの”Best”線形近似</a></li>
      <li><a href="#%E8%A7%A3%E9%87%88-3-causal-model">解釈 3: Causal Model</a>
        <ul>
          <li><a href="#att-and-selection-bias">ATT and selection bias</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#2-ordinary-least-squares-estimator">2. Ordinary Least Squares Estimator</a>
    <ul>
      <li><a href="#the-residual%E3%81%A8the-error-term%E3%81%AE%E9%81%95%E3%81%84">The residualとThe error termの違い</a></li>
      <li><a href="#demeaned-regressors">Demeaned Regressors</a></li>
      <li><a href="#projection-matrix">Projection Matrix</a></li>
      <li><a href="#residual-regression-fwl-theorem">Residual Regression: FWL theorem</a></li>
      <li><a href="#leverage-values">Leverage Values</a>
        <ul>
          <li><a href="#the-leverage%E3%81%AE%EF%BC%93%E3%81%A4%E3%81%AE%E6%80%A7%E8%B3%AA">the leverageの３つの性質</a></li>
          <li><a href="#leave-one-out-regression">Leave-One-Out Regression</a></li>
        </ul>
      </li>
      <li><a href="#goodness-of-fit-measure">Goodness of fit measure</a>
        <ul>
          <li><a href="#regressor%E3%81%A8r-squared%E3%81%AE%E9%96%A2%E4%BF%82">RegressorとR-squaredの関係</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#3-property-of-ols-estimator">3. Property of OLS Estimator</a>
    <ul>
      <li><a href="#assumptions">Assumptions</a></li>
      <li><a href="#unbiasedness">Unbiasedness</a></li>
      <li><a href="#conditional-variance-of-ols-estimator">Conditional Variance of OLS estimator</a></li>
      <li><a href="#gauss-markov-theorem">Gauss-Markov Theorem</a></li>
    </ul>
  </li>
  <li><a href="#4-asymptotic-property-of-ols-estimator">4. Asymptotic Property of OLS Estimator</a></li>
</ul>

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

<h2 id="1-linear-regressionの解釈">1. Linear Regressionの解釈</h2>

<p>$(Y_i, X_i, U_i)$をrandom vectorで、$Y_i, U_i \in \mathbf R$, $X_i \in \mathbf R^{k+1}$とします. $X$の最初の要素は定数1とします、つまり、</p>

\[X_i = (X_{i0}, \cdots, X_{ik})' \: \text{ with } X_{i0} = 1\]

<p>このとき、以下の線型回帰問題を考えます.</p>

\[Y_i = X_i'\beta + U_i\]

<p>この$\beta$は以下の推定量を解くことで得られます.</p>

\[\beta = \arg\min_{b} E[(Y_i - X_i'b)] \tag{1-1}\]

<p>(1-1) のFOCをとると</p>

<div class="math display" style="overflow: auto">
  <p>\(E[X_i(Y_i - X_i'b)] = 0 \Rightarrow \beta = E[X_iX_i']^{-1}E[X_iY_i] \tag{1-2}\)</p>
</div>

<p>この$\beta$の解釈をまず解説します.</p>

<h3 id="解釈-1-linear-conditional-expectations">解釈 1: Linear Conditional Expectations</h3>

<p>The CEFが線形であると仮定します, i.e., 
$E[Y_i|X_i] = X_i’\beta^*$ and $U_i = Y_i - E[Y_i|X_i]$. また、$E[|Y|] &lt; \infty$とします</p>

<blockquote>
  <p>Theorem 1-1: THE CEF Decomposition Property</p>
</blockquote>

\[Y_i = E[Y_i|X_i] + U_i\]

<p>このとき、$E[U_i|X_i] = 0$である. また、$U_i$はいかなる$X_i$の関数とは無相関である.</p>

<blockquote>
  <p>Proof</p>
</blockquote>

\[\begin{aligned}
E[U_i|X_i] &amp; = E[Y_i - E[Y_i|X_i]|X_i]\\
&amp; = E[Y_i|X_i] -  E[Y_i|X_i]\\
&amp; = 0
\end{aligned}\]

<p>またこのことより、</p>

\[\begin{aligned}
E[U_i] &amp;= \int f_x(t)E[U_i|X_i = t]dt\\
&amp;= 0 \times \int f_x(t) dt\\
&amp;= 0
\end{aligned}\]

<p>定理の後者の命題については、</p>

\[\begin{aligned}
E[h(X_i)U_i] &amp;= E[h(X_i)E[U_i|X_i]]\\
&amp;= 0
\end{aligned}\]

<div style="text-align: right;">
  <p>■</p>
</div>

<blockquote>
  <p>Theorem 1-3: THE CEF Prediction Property</p>
</blockquote>

<p>$m(X_i)$をany function of $X_i$とします. The CEFは以下の最小化問題の解と一致する:</p>

\[E[Y_i|X_i] = \arg\min_{m(X_i)} E[(Y_i - m(X_i))^2]\]

<blockquote>
  <p>Proof</p>
</blockquote>

<div class="math display" style="overflow: auto">
  <p>\(\begin{aligned}
E[(Y_i - m(X_i))^2] &amp;= E[(Y_i - E[Y_i|X_i] + E[Y_i|X_i] - m(X_i))^2]\\
&amp;= E[(Y_i - E[Y_i|X_i])^2] + E[2(Y_i - E[Y_i|X_i])(E[Y_i|X_i] - m(X_i))] + E[(E[Y_i|X_i] - m(X_i))^2]\\
&amp;= E[(E[Y_i|X_i] - m(X_i))^2]
\end{aligned}\)</p>
</div>

<div style="text-align: right;">
  <p>■</p>
</div>

<blockquote>
  <p>Theorem 1-3: THE Linear CEF theorem</p>
</blockquote>

<p>the CEFがLinearのとき、\(X_i'\beta\)はthe CEFそのものである.</p>

<blockquote>
  <p>Proof</p>
</blockquote>

<p>$E[Y_i|X_i] = X_i’\beta^*$と仮定します. このとき、定理1-1より</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{aligned}
&amp;E[X_i(Y_i - E[Y_i|X_i])] = 0\\
&amp;\Rightarrow E[X_i(Y_i - X_i'\beta^*)] = E[X_iY_i] - E[X_iX_i']\beta^* = 0
\end{aligned}\)</p>
</div>

<p>よって
\(\beta^* = E[X_iX_i']^{-1}E[X_iY_i] = \beta\)</p>

<div style="text-align: right;">
  <p>■</p>
</div>

<p>このとき、the CEFが推定できたことを以て、\(\beta_k\)を$X_{ik}$が\(Y_i\)に与える因果の意味での効果(the centeris paribus)と解釈したくなりますが、これは間違いです. あくまで\(\beta\)は \((Y_i, X_i)\) の同時分布の情報を集約した数値であり、必ずしもそれは因果の関係性を意味するわけではありません. 例えば、\(Y_i\)を個人の年間収入、\(X_i\)を年間所得税納付金額としたとき、$E[Y_i|X_i]$が上昇すればするほど、\(X_i\)は上がると考えられますが、その逆はthe centeris paribusの意味において考えることは一般的には難しいです.</p>

<h3 id="解釈-2-the-cefのbest線形近似">解釈 2: The CEFの”Best”線形近似</h3>

<blockquote>
  <p>Theorem 2-1: The BEST MMSE linear approximation</p>
</blockquote>

<p>The function \(X_i'\beta\)はthe CEFのthe MMSE linear approximationである, i.e.,</p>

\[\beta = \arg\min_{b} E\{(E[Y_i|X_i] - X_i'b)^2\}\]

<blockquote>
  <p>Proof</p>
</blockquote>

<div class="math display" style="overflow: auto">
  <p>\(\begin{aligned}
E\{(E[Y_i|X_i] - X_i'b)^2\} &amp;= E\{(Y - E[Y_i|X_i])^2 + 2(Y - E[Y_i|X_i])(Y - X_i'b) +(Y - X_i'b)^2 \} \\
&amp;= E[U_i^2] + 2E[U_iY_i] + E[(Y - X_i'b)^2]\\
&amp;= \text{ constant } + E[(Y - X_i'b)^2]
\end{aligned}\)</p>
</div>

<p>従って、</p>

<div class="math display" style="overflow: auto">
  <p>\(\arg\min_{b} E\{(E[Y_i|X_i] - X_i'b)^2\} = \arg\min_{b} E[(Y - X_i'b)^2]\)</p>
</div>

<div style="text-align: right;">
  <p>■</p>
</div>

<p>なお$\beta$がThe BEST MMSE linear approximationであることは以下の式からもわかります</p>

<div class="math display" style="overflow: auto">
  <p>\(\beta = E[X_iX_i']^{-1}E[X_iY_i] = E[X_iX_i']^{-1}E[X_iE(Y_i|X_i)]\)</p>
</div>

<blockquote>
  <p>Approxiamtionはsupportに依存する</p>
</blockquote>

<p>$\text{Supp}(X)$をrandom vector $X$のサポートと定義します. このとき</p>

<div class="math display" style="overflow: auto">
  <p>\(E\{(E[Y_i|X_i] - X_i'b)^2\} = \int_{x\in \text{Supp}(X)} (E[Y|X = x] - x'b)^2f_X(x)dx\)</p>
</div>

<p>よって、</p>

<ul>
  <li>the approximationは$X$の分布に依存する</li>
  <li>finite sampleにおいて、$X$のdataが観測されないエリアではthe approximationのweightはゼロになる</li>
  <li>$\text{Supp}(X)$が非常に狭い範囲の場合、finite sampleにおいて the approximationは非常に不安定になる</li>
</ul>

<h3 id="解釈-3-causal-model">解釈 3: Causal Model</h3>

<p>$(Y_i, D_i)$のrandom vectorからなるデータを考えます. $Y_i$はthe outcome, $D_i$はtreatment statusを示すbinary変数とします. このとき、$D_i$と$Y_i$のthe causal relationshipはthe potential outcomeを用いて記述することができます;</p>

\[Y = \begin{cases}
Y_{1i} &amp;\text{ if } D_i = 1\\
Y_{0i} &amp;\text{ if } D_i = 0
\end{cases}\]

<p>このときのthe treatment effectは</p>

\[\theta_i \equiv Y_{1i} - Y_{0i}\]

<p>と記述することができます. この設定の下、$(Y_i, D_i)$の単回帰モデルを考えてみます.</p>

\[Y_i = \alpha + \beta D_i + \eta_i\]

<p>このとき、</p>

<ul>
  <li>$\alpha = E[Y_{0i}]$</li>
  <li>$\beta  = E[\theta_i]$</li>
  <li>$\eta_i = Y_{0i} - E[Y_{0i}]$</li>
</ul>

<p>と対応付けて解釈することができます. The treatment statusごとにそれぞれのthe CEFを評価すると</p>

\[\begin{aligned}
E[Y_i|D_i=1]&amp;=\alpha + \beta + E[\eta_i|D_i = 1]\\
E[Y_i|D_i=0]&amp;=\alpha + E[\eta_i|D_i = 0]
\end{aligned}\]

<p>よって、</p>

<div class="math display" style="overflow: auto">
  <p>\(E[Y_i|D_i = 1] - E[Y_i|D_i = 1] = \beta + E[\eta_i|D_i = 1] - E[\eta_i|D_i = 0] \quad\quad\tag{1-3}\)</p>
</div>

<p>とATE + selection biasの関係性が見えてきます. 仮に $\eta_i \perp D_i$が成立している場合、(1-3)のselection biasの項が消えるので、単回帰モデルでATEが推定できることがわかります.</p>

<h4 id="att-and-selection-bias">ATT and selection bias</h4>

<ul>
  <li>$y$: the outcome variable</li>
  <li>$\mathbf x$: a set of explanatrory variables</li>
  <li>$s$: a treatment status indicator</li>
  <li>$\mu_0(\mathbf x) = E[y|\mathbf x, s= 0]$</li>
  <li>$\mu_1(\mathbf x) = E[y|\mathbf x, s= 1]$</li>
</ul>

<p>このとき、treatment statusに応じたグループ間の差分はATT + selection biasで表現できます.</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{aligned}
E[y|s=1] - E[y|s=0] &amp;= E[E[y|\mathbf x, s = 1]|s=1] - E[E[y|\mathbf x, s = 0]|s=0]\\
&amp;= E[\mu_1(\mathbf x)|s=1] - E[\mu_0(\mathbf x)|s=0]\\
&amp;= \underbrace{\left(E[\mu_1(\mathbf x)|s=1] - E[\mu_0(\mathbf x)|s=1] \right)}_{\text{ATT}} + \underbrace{\left(E[\mu_0(\mathbf x)|s=1] - E[\mu_0(\mathbf x)|s=0]\right)}_{\text{selection bias}}
\end{aligned}\)</p>
</div>

<p>次に、$\mu_s(\mathbf x) = \mathbf x\beta_s$とします.</p>

\[E[y|s=1] - E[y|s=0] = E[\mathbf x|s=1](\beta_1 - \beta_0) + \left(E[\mathbf x|s=1]-E[\mathbf x|s=0]\right)\beta_0\]

<h2 id="2-ordinary-least-squares-estimator">2. Ordinary Least Squares Estimator</h2>

<p>The CEFが$E[Y_i|X_i] = X_i’\beta$だと仮定します. このときの$\beta$を推定するためには</p>

\[\beta = \arg\min_b E[(Y_i - X_i'b)^2] \tag{2-1}\]

<p>を解けばよいこととなります. しかし、the joint distribution $(Y_i, X_i)$は事前には知られていないので、我々はこのthe sample analogで$\beta$を推定します.</p>

\[\hat\beta = \arg\min_b \frac{1}{N}\sum_{i=1}^N(Y_i - X_i'b)^2 \tag{2-2}\]

<p>$\mathbf Y = (Y_1, \cdots, Y_N)’, \mathbf X = (X_1, \cdots, X_N)’$とすると、(2-2)は次のような最小化問題に書き換えられます</p>

\[(\mathbf Y - \mathbf X b)'(\mathbf Y - \mathbf X b) \tag{2-3}\]

<p>(2-3)について、$b$のFOCをとると</p>

\[-\mathbf X'(\mathbf Y - \mathbf X \hat\beta) = 0 \tag{2-4}\]

<p>$\mathbf X$がfull rankであるならば$\mathbf X’\mathbf X$の逆行列がとれるので</p>

\[\hat\beta = (\mathbf X'\mathbf X)^{-1}\mathbf X\mathbf Y\tag{2-5}\]

<p>残差を $e_i \equiv Y - X_i’ \hat\beta$と定義したとき、(2-5)より</p>

\[\sum_{i=1}^N X_i e_i = \mathbf X'\mathbf e = 0 \tag{2-6}\]

<p>(2-6)が意味することは</p>

<ul>
  <li>$\mathbf X, \mathbf e$は直交</li>
  <li>$\mathbf X, \mathbf e$は無相関</li>
</ul>

<h3 id="the-residualとthe-error-termの違い">The residualとThe error termの違い</h3>

<p>上記(2-6)の内容を深堀したいと思います.</p>

\[\begin{aligned}
y_i = 1 + x_{1i} + x_{2i} + \epsilon_i
\end{aligned}\]

<ul>
  <li>$x_{1i}, x_{2i}, \epsilon_i$  are mutually independent standard normal random variables</li>
</ul>

<p>という回帰モデルを考えます. Finite sampleのもとでは、OLS residualはregressorsと直交していますが、the true error termは必ずしも直交していません. Pythonコードで見ていきたいと思います.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="c1">## set seed
</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1">## Data Generation
</span><span class="n">const</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">1000</span><span class="p">,</span> <span class="n">ndmin</span><span class="o">=</span><span class="mi">2</span><span class="p">).</span><span class="n">T</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">const</span><span class="p">,</span> <span class="n">data</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">coefficient_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">ndmin</span><span class="o">=</span><span class="mi">2</span><span class="p">).</span><span class="n">T</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">data</span> <span class="o">@</span> <span class="n">coefficient_matrix</span>

<span class="c1">## OLS
</span><span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">beta_ols</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">X</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>
<span class="n">residual</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">X</span> <span class="o">@</span> <span class="n">beta_ols</span>

<span class="c1">## regressor and residual
</span><span class="n">observed_data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">data</span><span class="p">,</span> <span class="n">residual</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1">## Covariance matrix
</span><span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">cov</span><span class="p">(</span><span class="n">observed_data</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s">'g'</span><span class="p">);</span>
<span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">cov</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">rowvar</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s">'g'</span><span class="p">);</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><img src="https://github.com/ryonakimageserver/omorikaizuka/blob/master/%E3%83%96%E3%83%AD%E3%82%B0%E7%94%A8/20211101_OLSresidual_and_true_error_covariancematrix.png?raw=true" /></p>

<h3 id="demeaned-regressors">Demeaned Regressors</h3>

\[Y_i = \alpha + X_i'\beta + \epsilon_i\]

<p>というモデルをOLSで推定したいときの結果を以下のように表すとします:</p>

\[Y_i = \hat\alpha + X_i'\hat\beta + e_i \tag{2-7}\]

<p>残差とFOCの性質より、</p>

\[\begin{align*}
\sum_{i=1}^N e_i &amp;= 0\tag{2-8}\\
\sum X_i(Y_i- \hat\alpha + X_i'\hat\beta)&amp;=0\tag{2-9}
\end{align*}\]

<p>(2-8)の式より</p>

\[\hat\alpha = \bar Y - \bar X'\hat\beta \tag{2-10}\]

<p>(2-10)を(2-9)の式に代入すると$\sum X_i(Y_i- \bar Y + (X_i’ - \bar X)\hat\beta)=0$を得る.</p>

<p>これを$\hat\beta$について解くと</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
\hat\beta &amp;= \left(\sum_{i=1}X_i\left(X_i - \bar X\right)'\right)^{-1}\left(\sum_{i=1}X_i\left(Y_i - \bar Y\right)\right)\\
&amp;= \left(\sum_{i=1}\left(X_i - \bar X\right)\left(X_i - \bar X\right)'\right)^{-1}\left(\sum_{i=1}\left(X_i - \bar X\right)\left(Y_i - \bar Y\right)\right)
\end{align*}\)</p>
</div>

<ul>
  <li>この推定量をthe demeaned formula for the least squares estimatorといいます</li>
  <li>OLS regressionで得られる推定量はdemeaned dataについてinterceptなしでOLS regressionを実行した場合に得られる推定量と一致します</li>
  <li>sample analogではstandard errorの数値が自由度の関係から微妙に異なってしまう</li>
</ul>

<blockquote>
  <p>standard errorの比較: OLS estimator vs demeaned OLS estimator</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1">## READ DATA
</span><span class="n">duncan_prestige</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="n">get_rdataset</span><span class="p">(</span><span class="s">"Duncan"</span><span class="p">,</span> <span class="s">"carData"</span><span class="p">)</span>

<span class="c1">## preprocessing
#----- model 1
</span><span class="n">Y</span> <span class="o">=</span> <span class="n">duncan_prestige</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="s">'income'</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">duncan_prestige</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="s">'education'</span><span class="p">]</span>

<span class="n">X_naive</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1">#------ demeaned data
</span><span class="n">Y_demeaned</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">Y</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">X_demeaned</span> <span class="o">=</span> <span class="n">X</span> <span class="o">-</span> <span class="n">X</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span>

<span class="c1">## Fitting
</span><span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="n">X_naive</span><span class="p">)</span>
<span class="n">model_demeaned</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">Y_demeaned</span><span class="p">,</span><span class="n">X_demeaned</span><span class="p">)</span>
<span class="n">results</span><span class="p">,</span> <span class="n">results_demeaned</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(),</span> <span class="n">model_demeaned</span><span class="p">.</span><span class="n">fit</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="n">results</span><span class="p">.</span><span class="n">summary</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">results_demeaned</span><span class="p">.</span><span class="n">summary</span><span class="p">())</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Then, The results are</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
</pre></td><td class="rouge-code"><pre>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 income   R-squared:                       0.525
Model:                            OLS   Adj. R-squared:                  0.514
Method:                 Least Squares   F-statistic:                     47.51
Date:                xxx, dd mmm yyyy   Prob (F-statistic):           1.84e-08
Time:                        01:43:38   Log-Likelihood:                -190.42
No. Observations:                  45   AIC:                             384.8
Df Residuals:                      43   BIC:                             388.5
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         10.6035      5.198      2.040      0.048       0.120      21.087
education      0.5949      0.086      6.893      0.000       0.421       0.769
==============================================================================
Omnibus:                        9.841   Durbin-Watson:                   1.736
Prob(Omnibus):                  0.007   Jarque-Bera (JB):               10.609
Skew:                           0.776   Prob(JB):                      0.00497
Kurtosis:                       4.802   Cond. No.                         123.
==============================================================================



                              Demeaned OLS Regression Results                                
=======================================================================================
Dep. Variable:                 income   R-squared (uncentered):                   0.525
Model:                            OLS   Adj. R-squared (uncentered):              0.514
Method:                 Least Squares   F-statistic:                              48.62
Date:                xxx, dd mmm yyyy   Prob (F-statistic):                    1.25e-08
Time:                        01:43:17   Log-Likelihood:                         -190.42
No. Observations:                  45   AIC:                                      382.8
Df Residuals:                      44   BIC:                                      384.6
Df Model:                           1                                                  
Covariance Type:            nonrobust                                                  
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
education      0.5949      0.085      6.972      0.000       0.423       0.767
==============================================================================
Omnibus:                        9.841   Durbin-Watson:                   1.736
Prob(Omnibus):                  0.007   Jarque-Bera (JB):               10.609
Skew:                           0.776   Prob(JB):                      0.00497
Kurtosis:                       4.802   Cond. No.                         1.00
==============================================================================

</pre></td></tr></tbody></table></code></pre></div></div>

<h3 id="projection-matrix">Projection Matrix</h3>

<p>次に線形代数の射影の観点からOLS estimatorの性質を考えます. $\mathbf Y = \mathbf X \beta + \epsilon$というモデルを考えます.</p>

<p>このとき、$\mathbf X$で張られるfieldへの射影を実行する射影行列(projection matrix) $\mathbf P$を以下のように定義します:</p>

\[\mathbf P \equiv \mathbf X(\mathbf X'\mathbf X)^{-1}\mathbf X'\]

<p>また残差行列 $M$を次のように定義します</p>

\[M \equiv (I - P)\]

<p><strong>射影行列の性質</strong></p>

<blockquote>
  <p>1: $\mathbf X$を$\mathbf P$で射影すると自分自身になる</p>
</blockquote>

\[\mathbf P \mathbf X = \mathbf X(\mathbf X'\mathbf X)^{-1}\mathbf X' \mathbf X = \mathbf X\]

<div style="text-align: right;">
  <p>■</p>
</div>

<blockquote>
  <p>2: $\mathbf X = [X_1, X_2]$としたときをsubvector $X_1$を$\mathbf P$で射影すると自分自身になる</p>
</blockquote>

<p>射影行列$P$について</p>

\[\begin{align*}
P &amp; = \mathbf X(\mathbf X'\mathbf X)^{-1}\mathbf X'\\
&amp;= [X_1 X_2]\left(\left[\begin{array}{c}X_1'\\X_2'\end{array}\right][X_1, X_2]\right)^{-1}\left[\begin{array}{c}X_1'\\X_2'\end{array}\right]\\
&amp;=[X_1 X_2]\left(\begin{array}{cc}X_1'X_1 &amp; X_1'X_2\\X_2'X_1 &amp; X_2'X_2\end{array}\right)^{-1}\left[\begin{array}{c}X_1'\\X_2'\end{array}\right]  \tag{2-11}
\end{align*}\]

<p>表記の簡略化のため</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
&amp;\left(\begin{array}{cc}X_1'X_1 &amp; X_1'X_2\\X_2'X_1 &amp; X_2'X_2\end{array}\right)^{-1}\\
&amp;\equiv \left(\begin{array}{cc}Q_{11} &amp; Q_{12}\\Q_{21} &amp; Q_{22}\end{array}\right)^{-1}\\
&amp;= \left(\begin{array}{cc}Q_{11\cdot 2}^{-1} &amp; -Q_{11\cdot 2}^{-1}Q_{12}Q_{21}^{-1}\\-Q_{22\cdot 1}^{-1}Q_{21}Q_{11}^{-1} &amp; Q_{22\cdot 1}^{-1}\end{array}\right)\tag{2-12}
\end{align*}\)</p>
</div>

<p>このとき</p>

\[\begin{align*}
Q_{11\cdot 2} &amp;= Q_{11} - Q_{12}Q_{22}^{-1}Q_{21} = X_1'M_2X_1\\ 
Q_{22\cdot 1} &amp;= Q_{22} - Q_{21}Q_{11}^{-1}Q_{12} = X_2'M_1X_2
\end{align*}\]

<p>よって,</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
\left(\begin{array}{cc}X_1'X_1 &amp; X_1'X_2\\X_2'X_1 &amp; X_2'X_2\end{array}\right)^{-1}\left[\begin{array}{c}X_1'\\X_2'\end{array}\right]X_1
&amp;=\left(\begin{array}{cc}(X_1'M_2X_1)^{-1} &amp; -(X_1'M_2X_1)^{-1}X_1'X_2(X_2'X_2)^{-1}\\
-(X_2'M_1X_2)^{-1}X_2'X_1(X_1'X_1)^{-1} &amp; (X_2'M_1X_2)^{-1}\end{array}\right)\left[\begin{array}{c}X_1'X_1 \\X_2'X_1\end{array}\right]\\
&amp;= \left(\begin{array}{c}(X_1'M_2X_1)^{-1}(X_1'M_2X_1)\\ (X_1'M_2X_1)^{-1}X_2'X_1 - (X_1'M_2X_1)^{-1}(X_2'P_1X_1) \end{array}\right)\\
&amp;= \left(\begin{array}{c}1\\ 0 \end{array}\right)\tag{2-13}
\end{align*}\)</p>
</div>

<p>(2-13)の結果を用いると</p>

\[\begin{aligned}
PX_1 &amp;= [X_1 X_2] \left(\begin{array}{cc}X_1'X_1 &amp; X_1'X_2\\X_2'X_1 &amp; X_2'X_2\end{array}\right)^{-1}\left[\begin{array}{c}X_1'\\X_2'\end{array}\right]X_1\\
&amp;= [X_1 X_2]\left(\begin{array}{c}1\\ 0 \end{array}\right)\\
&amp;= X_1
\end{aligned}\]

<div style="text-align: right;">
  <p>■</p>
</div>

<h3 id="residual-regression-fwl-theorem">Residual Regression: FWL theorem</h3>

\[Y = X_1\hat\beta_1 + \cdots + X_K\hat\beta_K + \hat e \tag{2-14}\]

<p>というOLS estimatorを考えます. ここで$X_1$を$(X_2, \cdots X_K)$に回帰します.</p>

\[\begin{align*}
X_1 &amp;= X_2\hat\alpha_2 + \cdots + X_K\hat\alpha_K + \hat V\\
&amp;= \hat X_1 + \hat V \tag{2-15}
\end{align*}\]

<p>(2-14)の両辺に $\hat V’$を左から掛けます:</p>

\[\begin{align*}
\hat V'Y &amp;= \hat V'(X_1\hat\beta_1 + \cdots + X_K\hat\beta_K + \hat e)\\
&amp;= \hat V'X_1\hat\beta_1\\
&amp;= \hat V'(\hat X_1 + \hat V)\hat\beta_1\\
&amp;= \hat V'\hat V\beta_1 \tag{2-16}
\end{align*}\]

<p>よって $\hat V’\hat V$の逆行列が存在する時</p>

\[(\hat V'\hat V)^{-1}\hat V'Y = \hat\beta_1 \tag{2-17}\]

<p>このような残差回帰で$\hat\beta$のsubvectorを推定できる性質のことをFWL定理といいます. なお、射影行列を用いると$\hat V$は以下のように表現できます</p>

\[\hat V = (I - P_{2K})X_1 = M_{2k}X_1 \tag{2-18}\]

<p>(2-17)に(2-18)を代入すると</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
&amp;(\hat V'\hat V)^{-1}\hat V'Y  \\
&amp;= (X_1'M_{2k}X_1)^{-1}X_1'M_{2k}Y\\
&amp;= (X_1'M_{2k}'M_{2k}X_1)^{-1}X_1'M_{2k}'M_{2k}Y\tag{2-19}
\end{align*}\)</p>
</div>

<p>(2-19)から$Y$を$(X_2, \cdots, X_K)$に回帰した残差を$X_1$を$(X_2, \cdots, X_K)$に回帰した残差すると$\hat\beta_1$が得られることがわかります. また、(25)の結果得られる残差と$\hat e$も一致します.</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{aligned}
(X_1'M_{2k}'M_{2k}X_1)^{-1}X_1'M_{2k}'M_{2k}Y &amp;= \hat\beta_1 + (X_1'M_{2k}'M_{2k}X_1)^{-1}X_1'M_{2k}'M_{2k}\hat e_i\\
&amp;= \hat\beta_1 + \hat e_i
\end{aligned}\)</p>
</div>
<div style="text-align: right;">
  <p>■</p>
</div>

<blockquote>
  <p>Coded example</p>
</blockquote>

\[\begin{aligned}
&amp;y_i = \beta x_i + z_i'\gamma + u_i \: \text{ where } i = 1, \cdots 10000 \\
&amp;(x_i, z_i) \sim N\left(\left(\begin{array}{c}0\\0\\0\\0 \end{array}\right), \left(\begin{array}{cccc}1 &amp; -1 &amp; 2 &amp; 0 \\-1 &amp; 4 &amp; -1 &amp; 1\\2&amp; -1 &amp; 6 &amp;-2 \\ 0 &amp; 1 &amp; -2 &amp; 4 \end{array}\right)\right)\\
&amp;u_i \sim N(0, 1)

\end{aligned}\]

<p>というregression modelを考えます. このとき, $\beta$をフルモデルのOLS, 残差回帰それぞれで以下推定します.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
</pre></td><td class="rouge-code"><pre><span class="n">mport</span> <span class="n">statsmodels</span><span class="p">.</span><span class="n">api</span> <span class="k">as</span> <span class="n">sm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1">## set seed
</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1">## parameter
</span><span class="n">N</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">mean</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">cov</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]</span>
<span class="n">beta</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]]).</span><span class="n">T</span>

<span class="c1">## data generation
</span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">hsplit</span><span class="p">(</span><span class="n">data</span><span class="p">,[</span><span class="mi">1</span><span class="p">,])</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">beta</span> <span class="o">+</span> <span class="n">z</span> <span class="o">@</span> <span class="n">gamma</span> <span class="o">+</span> <span class="n">u</span>

<span class="c1">## residuals: regress (y, x) on z and get each of the residuals
</span><span class="n">x_resid</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">z</span> <span class="o">@</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">inv</span><span class="p">(</span><span class="n">z</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">z</span><span class="p">)</span> <span class="o">@</span> <span class="n">z</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">x</span>
<span class="n">y_resid</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">z</span> <span class="o">@</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">inv</span><span class="p">(</span><span class="n">z</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">z</span><span class="p">)</span> <span class="o">@</span> <span class="n">z</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>

<span class="c1">## estimation
</span><span class="n">reg_ols</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">data</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">reg_ols</span><span class="p">.</span><span class="n">fit</span><span class="p">()</span>

<span class="n">reg_resid_1</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">x_resid</span><span class="p">)</span>
<span class="n">results_resid_1</span> <span class="o">=</span> <span class="n">reg_resid_1</span><span class="p">.</span><span class="n">fit</span><span class="p">()</span>

<span class="n">reg_resid_2</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y_resid</span><span class="p">,</span><span class="n">x_resid</span><span class="p">)</span>
<span class="n">results_resid_2</span> <span class="o">=</span> <span class="n">reg_resid_2</span><span class="p">.</span><span class="n">fit</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Then,</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
</pre></td><td class="rouge-code"><pre>                                 OLS Regression Results                                
=======================================================================================
Dep. Variable:                      y   R-squared (uncentered):                   0.990
Model:                            OLS   Adj. R-squared (uncentered):              0.990
Method:                 Least Squares   F-statistic:                          2.466e+05
Date:                xxx, dd mmm yyyy   Prob (F-statistic):                        0.00
Time:                        03:49:15   Log-Likelihood:                         -14191.
No. Observations:               10000   AIC:                                  2.839e+04
Df Residuals:                    9996   BIC:                                  2.842e+04
Df Model:                           4                                                  
Covariance Type:            nonrobust                                                  
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.9261      0.061     15.187      0.000       0.807       1.046
x2             1.9852      0.014    139.290      0.000       1.957       2.013
x3             3.0339      0.023    129.403      0.000       2.988       3.080
x4             4.0271      0.016    253.591      0.000       3.996       4.058
==============================================================================

                                 Residual Regression Part 1 Results                                
=======================================================================================
Dep. Variable:                      y   R-squared (uncentered):                   0.000
Model:                            OLS   Adj. R-squared (uncentered):              0.000
Method:                 Least Squares   F-statistic:                              2.315
Date:                xxx, dd mmm yyyy   Prob (F-statistic):                       0.128
Time:                        03:49:21   Log-Likelihood:                         -37200.
No. Observations:               10000   AIC:                                  7.440e+04
Df Residuals:                    9999   BIC:                                  7.441e+04
Df Model:                           1                                                  
Covariance Type:            nonrobust                                                  
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.9261      0.609      1.521      0.128      -0.267       2.119
==============================================================================


                              Residual Regression Part 2 Results                                
=======================================================================================
Dep. Variable:                      y   R-squared (uncentered):                   0.023
Model:                            OLS   Adj. R-squared (uncentered):              0.022
Method:                 Least Squares   F-statistic:                              230.7
Date:                xxx, dd mmm yyyy   Prob (F-statistic):                    1.57e-51
Time:                        03:49:29   Log-Likelihood:                         -14191.
No. Observations:               10000   AIC:                                  2.838e+04
Df Residuals:                    9999   BIC:                                  2.839e+04
Df Model:                           1                                                  
Covariance Type:            nonrobust                                                  
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1             0.9261      0.061     15.189      0.000       0.807       1.046
==============================================================================

</pre></td></tr></tbody></table></code></pre></div></div>

<ul>
  <li>Degree of Freedomがモデルによって異なるので$\hat\beta_1$の値が一致してもstandard errorが異なる</li>
  <li>R-squaredも $1 - \text{RSS}/\text{TSS} = \text{ESS}/\text{TSS}$という定義より、値が異なってくる</li>
</ul>

<blockquote>
  <p>練習問題: Partially Linear Model, Robinson Estomator 1988</p>
</blockquote>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
y &amp;= E[y|\mathbf x, \mathbf z] + u\tag{26}\\
E[y|\mathbf x, \mathbf z] &amp;= g(\mathbf x) + \mathbf z\beta\tag{27}\\
E[u|\mathbf x, \mathbf z] &amp; = 0\tag{28}
\end{align*}\)</p>
</div>

<ul>
  <li>$g(\cdot)$: a general function of $\mathbf x$</li>
  <li>$\beta$: $ 1 \times M$ vector</li>
</ul>

<p>というモデルを考えます. このとき、以下を証明せよ</p>

\[E[\tilde y|\tilde{\mathbf z}] = \tilde{\mathbf z}\beta\]

<ul>
  <li>$\tilde y \equiv y - E[y|\mathbf x]$</li>
  <li>$\tilde y \equiv \mathbf z - E[\mathbf z|\mathbf x]$</li>
</ul>

<blockquote>
  <p>証明</p>
</blockquote>

<p>$E[y|\mathbf x]$についてまず考えます. (28)より$E[u|\mathbf x] = E[E[y|\mathbf x, \mathbf z]|\mathbf x] =0$. 従って、</p>

\[E[y|\mathbf x] = g(\mathbf x) + E[\mathbf z|\mathbf x]\beta \tag{29}\]

<p>(26) - (29)より</p>

\[y - E[y|\mathbf x] = (\mathbf z - E[\mathbf z|\mathbf x])\beta\tag{30}\]

<p>この推定量は$E[y|\mathbf x], E[\mathbf z|\mathbf x]$をnonparametricに推定し、それを用いて$y, \mathbf z$のresidualをそれぞれ計算. そのresidualsを用いてOLS regressionをするという形で計算します. この推定量から得られる$\hat\beta$は$\sqrt N$-consistent, asymptotically normalであることが知られています.</p>

<div style="text-align: right;">
  <p>■</p>
</div>

<blockquote>
  <p>Python simulation</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
</pre></td><td class="rouge-code"><pre><span class="n">mport</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="n">smf</span>
<span class="kn">from</span> <span class="nn">statsmodels.sandbox.regression.predstd</span> <span class="kn">import</span> <span class="n">wls_prediction_std</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="p">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s">'ignore'</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">style</span>
<span class="n">style</span><span class="p">.</span><span class="n">use</span><span class="p">(</span><span class="s">"fivethirtyeight"</span><span class="p">)</span>

<span class="c1">## set seed
</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1">## parameter
</span><span class="n">N</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">mean</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">cov</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">]]</span>
<span class="n">beta</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">]]).</span><span class="n">T</span>
<span class="n">lottery</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>

<span class="c1">## data generation
</span><span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span>
<span class="n">z_1</span><span class="p">,</span> <span class="n">z_2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">hsplit</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,])</span>
<span class="n">D_hat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">Z</span> <span class="o">@</span> <span class="n">gamma</span><span class="p">)</span><span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">Z</span> <span class="o">@</span> <span class="n">gamma</span><span class="p">))</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">int64</span><span class="p">(</span><span class="n">lottery</span> <span class="o">&lt;</span> <span class="n">D_hat</span><span class="p">.</span><span class="n">flatten</span><span class="p">()).</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">D</span> <span class="o">*</span> <span class="n">beta</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">z_1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">sin</span><span class="p">(</span><span class="n">z_1</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">-</span> <span class="n">z_1</span> <span class="o">**</span><span class="mi">3</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="n">cos</span><span class="p">(</span><span class="n">z_2</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">e</span>

<span class="c1">## DataFrame
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">y</span><span class="p">,</span> <span class="n">D_hat</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">z_1</span><span class="p">,</span> <span class="n">z_2</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">),</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'y'</span><span class="p">,</span> <span class="s">'D_hat'</span><span class="p">,</span> <span class="s">'D'</span><span class="p">,</span> <span class="s">'z_1'</span><span class="p">,</span> <span class="s">'z_2'</span><span class="p">])</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>次に２グループの平均単純比較をします</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td><td class="rouge-code"><pre><span class="c1">## Naive estimator
</span><span class="n">naive</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">'D'</span><span class="p">)[</span><span class="s">'y'</span><span class="p">].</span><span class="n">mean</span><span class="p">().</span><span class="n">values</span>
<span class="n">naive</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">insert</span><span class="p">(</span><span class="n">naive</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">naive</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">naive</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">naive</span><span class="p">])</span>
<span class="n">res</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'control mean'</span><span class="p">,</span> <span class="s">'treated mean'</span><span class="p">,</span> <span class="s">'mean diff'</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Then</p>

<pre><code class="language-raw">   control mean  treated mean  mean diff
0      2.159487      3.543704   1.384217
</code></pre>

<p>OLS estimatesは</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="n">model_naive</span> <span class="o">=</span> <span class="n">smf</span><span class="p">.</span><span class="n">ols</span><span class="p">(</span><span class="s">'y ~ D + z_1 + z_2'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">).</span><span class="n">fit</span><span class="p">()</span>
<span class="n">model_naive</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Then</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td class="rouge-code"><pre> OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.567
Model:                            OLS   Adj. R-squared:                  0.566
Method:                 Least Squares   F-statistic:                     434.8
Date:                xxx, dd mmm yyyy   Prob (F-statistic):          1.71e-180
Time:                        23:45:28   Log-Likelihood:                -1945.3
No. Observations:                1000   AIC:                             3899.
Df Residuals:                     996   BIC:                             3918.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      1.9697      0.078     25.165      0.000       1.816       2.123
D              1.6919      0.112     15.043      0.000       1.471       1.913
z_1            3.7839      0.133     28.550      0.000       3.524       4.044
z_2            0.0196      0.080      0.247      0.805      -0.137       0.176
==============================================================================
</pre></td></tr></tbody></table></code></pre></div></div>

<p>最後にRobinson estimatorを実施します（簡易版）</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
</pre></td><td class="rouge-code"><pre><span class="c1">## Robinson Estimator
#--- kernel density estimator object
</span><span class="n">kernel_D</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">gaussian_kde</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">D</span><span class="p">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">z_1</span><span class="p">.</span><span class="n">ravel</span><span class="p">(),</span><span class="n">z_2</span><span class="p">.</span><span class="n">ravel</span><span class="p">()]),</span> <span class="n">bw_method</span><span class="o">=</span><span class="s">'silverman'</span><span class="p">)</span>
<span class="n">kernel_Y</span> <span class="o">=</span> <span class="n">stats</span><span class="p">.</span><span class="n">gaussian_kde</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">y</span><span class="p">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">z_1</span><span class="p">.</span><span class="n">ravel</span><span class="p">(),</span><span class="n">z_2</span><span class="p">.</span><span class="n">ravel</span><span class="p">()]),</span> <span class="n">bw_method</span><span class="o">=</span><span class="s">'silverman'</span><span class="p">)</span>

<span class="c1">#--- input data for kernel desity estimation
</span><span class="n">input_array</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s">'z_1'</span><span class="p">,</span> <span class="s">'z_2'</span><span class="p">]].</span><span class="n">values</span>
<span class="n">D_input_array_0</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">input_array</span><span class="p">])</span>
<span class="n">D_input_array_1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">input_array</span><span class="p">])</span>
<span class="n">y_range</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">round</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span><span class="o">-</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nb">round</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">+</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">3000</span><span class="p">)</span>
<span class="n">y_sample</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_range</span><span class="p">)</span>
<span class="n">y_kernel_hat</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1">#--- density estimation
</span><span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">input_array</span><span class="p">:</span>
    <span class="n">covariate_row_reshaped</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">tile</span><span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">y_sample</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="n">y_sample</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">input_array_y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">y_range</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">covariate_row_reshaped</span><span class="p">]).</span><span class="n">T</span>
    
    <span class="n">prob_array</span> <span class="o">=</span> <span class="n">kernel_Y</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">input_array_y</span><span class="p">.</span><span class="n">tolist</span><span class="p">()))</span>
    <span class="n">conditional_mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">y_range</span><span class="p">.</span><span class="n">ravel</span><span class="p">()</span> <span class="o">*</span> <span class="n">prob_array</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">prob_array</span><span class="p">)</span>
    
    <span class="n">y_kernel_hat</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">conditional_mean</span><span class="p">)</span>

<span class="n">df_fix</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">df_fix</span><span class="p">[</span><span class="s">'y_kernel_hat'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_kernel_hat</span><span class="p">)</span>
<span class="n">df_fix</span><span class="p">[</span><span class="s">'d_kernel_hat'</span><span class="p">]</span> <span class="o">=</span> <span class="n">kernel_D</span><span class="p">(</span><span class="n">D_input_array_1</span><span class="p">.</span><span class="n">T</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">kernel_D</span><span class="p">(</span><span class="n">D_input_array_0</span><span class="p">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">kernel_D</span><span class="p">(</span><span class="n">D_input_array_1</span><span class="p">.</span><span class="n">T</span><span class="p">))</span>
<span class="n">y_residual</span> <span class="o">=</span> <span class="n">df_fix</span><span class="p">[</span><span class="s">'y'</span><span class="p">]</span> <span class="o">-</span> <span class="n">df_fix</span><span class="p">[</span><span class="s">'y_kernel_hat'</span><span class="p">]</span>
<span class="n">d_residual</span> <span class="o">=</span> <span class="n">df_fix</span><span class="p">[</span><span class="s">'D'</span><span class="p">]</span> <span class="o">-</span> <span class="n">df_fix</span><span class="p">[</span><span class="s">'d_kernel_hat'</span><span class="p">]</span>

<span class="n">reg_robinson</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y_residual</span><span class="p">,</span><span class="n">d_residual</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">reg_robinson</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">use_t</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">cov_type</span><span class="o">=</span><span class="s">'HC2'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">results</span><span class="p">.</span><span class="n">summary</span><span class="p">())</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Then,</p>

<pre><code class="language-raw">                                OLS Regression Results                                
=======================================================================================
Dep. Variable:                      y   R-squared (uncentered):                   0.328
Model:                            OLS   Adj. R-squared (uncentered):              0.327
Method:                 Least Squares   F-statistic:                              505.5
Date:                xxx, dd mmm yyyy   Prob (F-statistic):                    6.58e-91
Time:                        23:41:23   Log-Likelihood:                         -1477.6
No. Observations:                1000   AIC:                                      2957.
Df Residuals:                     999   BIC:                                      2962.
Df Model:                           1                                                  
Covariance Type:                  HC2                                                  
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
x1             1.5968      0.071     22.483      0.000       1.457       1.736
==============================================================================
</code></pre>

<ul>
  <li>もともとのthe error termの分散によってkernel density estimationの精度が大きく変わってしまう点に留意</li>
</ul>

<div style="text-align: right;">
  <p>■</p>
</div>

<h3 id="leverage-values">Leverage Values</h3>

\[Y = X\beta + \epsilon\]

<ul>
  <li>$X: n\times k$ matrix</li>
  <li>$E[\epsilon|X] = 0$</li>
  <li>$\text{rank}(X) = k$</li>
</ul>

<p>というモデルを考えます. 射影行列の議論より、</p>

\[\hat Y = X(X'X)^{-1}X'Y\tag{31}\]

<p>(31)の射影行列はthe hat matrixともいい、</p>

\[\begin{align*}
H &amp;= X(X'X)^{-1}X' \tag{32}\\
H&amp; = (h_{ii}) \tag{33}
\end{align*}\]

<p>(31)と(33)を比較すると、</p>

<div class="math display" style="overflow: auto">
  <p>\(\hat{y}_i=h_{i1}y_1+h_{i2}y_2+...+h_{ii}y_i+ ... + h_{in}y_n  \;\;\;\;\; \text{ for } i=1, ..., n \tag{34}\)</p>
</div>

<p>つまり、$h_{ii}$はthe observed outcome, $\hat y_i$ が予測値に与える影響を数値化したものといえるため、$h_{ii}$ のことをthe leverageといいます.</p>

<blockquote>
  <p>REMARKS</p>
</blockquote>

<ul>
  <li>$h_{ii}$はデータポイントのx値とn個のデータポイントすべてのx値の平均との間の距離を表す指標と考えることもできます</li>
  <li>Outlier detectionで活用されることもあります</li>
  <li>$h_{ii}$ について簡単な計算をすると以下のことが示せます:</li>
</ul>

\[h_{ii} = X_i'(X'X)^{-1}X_i\tag{35}\]

<blockquote>
  <p>Python: The leverageとcovariateの関係</p>
</blockquote>

<p>「$h_{ij}$はデータポイントのx値とn個のデータポイントすべてのx値の平均との間の距離を表す指標」であることをPythonを用いて確認したいと思います.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="n">smf</span>

<span class="c1">## generating data
</span><span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0716</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.45401</span><span class="p">,</span> <span class="mf">4.1673</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mf">1.09765</span><span class="p">,</span>	<span class="mf">6.5703</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mf">1.27936</span><span class="p">,</span> <span class="mf">13.815</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mf">2.20611</span><span class="p">,</span> <span class="mf">11.4501</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mf">2.50064</span><span class="p">,</span> <span class="mf">12.9554</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mf">3.0403</span><span class="p">,</span> <span class="mf">20.1575</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mf">3.23583</span><span class="p">,</span> <span class="mf">17.5633</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mf">4.45308</span><span class="p">,</span> <span class="mf">26.0317</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mf">4.1699</span><span class="p">,</span> <span class="mf">22.7573</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mf">5.28474</span><span class="p">,</span> <span class="mf">26.303</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mf">5.59238</span><span class="p">,</span> <span class="mf">30.6885</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">13</span><span class="p">,</span> <span class="mf">5.92091</span><span class="p">,</span> <span class="mf">33.9402</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">14</span><span class="p">,</span> <span class="mf">6.66066</span><span class="p">,</span> <span class="mf">30.9228</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mf">6.79953</span><span class="p">,</span> <span class="mf">34.11</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mf">7.97943</span><span class="p">,</span> <span class="mf">44.4536</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">17</span><span class="p">,</span> <span class="mf">8.41536</span><span class="p">,</span> <span class="mf">46.5022</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">18</span><span class="p">,</span> <span class="mf">8.71607</span><span class="p">,</span> <span class="mf">50.0568</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">19</span><span class="p">,</span> <span class="mf">8.70156</span><span class="p">,</span> <span class="mf">46.5475</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mf">9.16463</span><span class="p">,</span> <span class="mf">45.7762</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">21</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">40</span><span class="p">]</span>
        <span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">'row'</span><span class="p">,</span> <span class="s">'x'</span><span class="p">,</span> <span class="s">'y'</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s">'const'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1">## compute the Hat matrix
</span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s">'const'</span><span class="p">,</span> <span class="s">'x'</span><span class="p">]].</span><span class="n">values</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">H_matrix</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">X</span><span class="p">.</span><span class="n">T</span>
<span class="n">df</span><span class="p">[</span><span class="s">'h_leverage'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">diag</span><span class="p">(</span><span class="n">H_matrix</span><span class="p">)</span>

<span class="c1">## the leverageとx valueの関係
</span><span class="n">ns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'x'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'h_leverage'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'x'</span><span class="p">]),</span> <span class="n">color</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">'dashed'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">min_ylim</span><span class="p">,</span> <span class="n">max_ylim</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">text</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'x'</span><span class="p">])</span><span class="o">*</span><span class="mf">1.1</span><span class="p">,</span> <span class="n">max_ylim</span><span class="o">*</span><span class="mf">0.9</span><span class="p">,</span> <span class="s">'x Mean: {:.2f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'x'</span><span class="p">])));</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Then,</p>

<p><img src="https://github.com/ryonakimageserver/omorikaizuka/blob/master/%E3%83%96%E3%83%AD%E3%82%B0%E7%94%A8/20211101_H_hat_matrix.png?raw=true" /></p>

<h4 id="the-leverageの３つの性質">the leverageの３つの性質</h4>

<blockquote>
  <p>Theorem</p>
</blockquote>

<ol>
  <li>$\sum_{i}^N h_{ii} = k$</li>
  <li>$0 \leq h_{ii} \leq 1$</li>
  <li>$h_{ii} \geq 1/n$ if an intercept is included</li>
</ol>

<blockquote>
  <p>Proof (1)</p>
</blockquote>

\[\begin{aligned}
\sum_{i}^N h_{ii} &amp;= tr(X(X'X)^{-1}X')\\
&amp;= tr((X'X)^{-1}X'X)\\
&amp;= k 
\end{aligned}\]

<div style="text-align: right;">
  <p>■</p>
</div>

<blockquote>
  <p>Proof (2)</p>
</blockquote>

<p>$H$は $H = HH$という性質を持っているので</p>

\[h_{ii} = \sum_{i=1}^N h_i^2\]

<p>従って、$h_{ii} \geq 0$. また、(1)より $\sum h_{ii} = k \leq n$なので$h_{ii}\leq 1$</p>

<div style="text-align: right;">
  <p>■</p>
</div>

<blockquote>
  <p>Proof (3)</p>
</blockquote>

<p>$X = [1, \hat X_i]$の場合を考えます.</p>

\[\begin{aligned}
h_{ii} &amp;= (1, \hat X_i')\left(\begin{array}{cc}n&amp;0\\0&amp;\hat X_i'\hat X_i\end{array}\right)^{-1}\left(\begin{array}{c}1\\ \hat X_i\end{array}\right)\\
&amp;= \frac{1}{n} + \hat X_i'(\hat X_i'\hat X_i)^{-1}\hat X_i \geq \frac{1}{n}
\end{aligned}\]

<div style="text-align: right;">
  <p>■</p>
</div>

<h4 id="leave-one-out-regression">Leave-One-Out Regression</h4>

\[Y = X\beta + \epsilon\]

<ul>
  <li>$X_i$: k vector for ith observation</li>
  <li>$E[\epsilon|X] = 0$</li>
</ul>

<p>というモデルを考えます. これをLeave-One-Out Regression(LOO)という手法で推定します. LOOとは、自分自身のobservationを除外したsub-sampleを用いてパラメータを推定し、そのパラメータを用いて自分自身のoutcomeを予測するという手法です.</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
\tilde \beta_{-i} &amp; = \left(\sum_{j\neq i}X_jX_j'\right)^{-1}\sum_{j\neq i}X_jY_j\\
&amp;= (X'X - X_i'X_i)^{-1}(X'Y - X_iY_i)\\
&amp;= (X_{-i}'X_{-i})^{-1}X_{-i}Y_{-i}\tag{36}
\end{align*}\)</p>
</div>

<p><strong>$\hat\beta$と$\tilde\beta_{-i}$の関係</strong></p>

<ul>
  <li>$\tilde e_i$: LOOを用いて得られたresidual</li>
  <li>$\hat e_i$: OLSで得られたresidual</li>
  <li>$h_{i}$: the hat matrixのi-th diagonal element</li>
</ul>

<p>このとき、いかが成り立ちます:</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
\tilde\beta_{-i} - \hat\beta &amp; = \left(\frac{\hat e_i}{1-h_i}\right)(X'X)^{-1}X_{-i} \tag{37}\\
&amp; = (X'X)^{-1}X_{-i}\tilde e_{i} \tag{38}
\end{align*}\)</p>
</div>

<blockquote>
  <p>(38)の証明</p>
</blockquote>

<p>まず以下の定理を所与とします：</p>

<ul>
  <li>A: non-singular matrix</li>
  <li>b: a vector</li>
  <li>$\lambda$: a scalar</li>
</ul>

<p>If</p>

\[\begin{align*}
 \lambda&amp;\neq -\frac{1}{b'A^{-1}b}
 \end{align*}\]

<p>Then,</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
(A+\lambda bb')^{-1}&amp;=A^{-1}-\left(\frac{\lambda}{1+\lambda b'A^{-1}b}\right)A^{-1}bb'A^{-1}\quad\quad   \textrm{(A)
}\end{align*}\)</p>
</div>

<p>次に、(36)で確認した$\tilde\beta_{-i}$計算の各項を見ていきます.</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
(X_{-i}'X_{-i})^{-1} &amp;= (X'X-X_iX_i')^{-1}\\
&amp;=(X'X)^{-1}+\frac{(X'X)^{-1}X_iX_i'(X'X)^{-1}}{1-X_i'(X'X)^{-1}X_i} \quad\quad \tag{39}
\end{align*}\)</p>
</div>

<p>(39)の両辺に右から$X_{i}$を掛けると</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
(X_{-i}'X_{-i})^{-1}X_i&amp;=(X'X)^{-1}X_i+(X'X)^{-1}X_i\left(\frac{X_i'(X'X)^{-1}X_i}{1-X_i'(X'X)^{-1}X_i}\right)\\
&amp;=\left(\frac{1}{1-h_{ii}}\right)(X'X)^{-1}X_i\quad\quad \tag{40}
\end{align*}\)</p>
</div>

<p>$\hat\beta$の関係式より</p>

\[(X'X)^{-1}\hat\beta = X'Y\]

<p>より</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
&amp;(X_{-i}'X_{-i} + X_iX_i')^{-1}\hat\beta = (X_{-i}'Y_{-i} + X_iY_i)\\
&amp;\Rightarrow (I_k + (X_{-i}X_{-i}')^{-1}X_iX_i')\hat\beta = \tilde\beta_{-i} + (X_{-i}X_{-i}')^{-1}X_i(X_i'\hat\beta + \hat e_i)\\
&amp;\Rightarrow \hat\beta = \tilde\beta_{-i}+(X_{-i}'X_{-i})^{-1}X_i\hat e_i \quad\quad \tag{41}
\end{align*}\)</p>
</div>

<div style="text-align: right;">
  <p>■</p>
</div>

<blockquote>
  <p>(37)の証明</p>
</blockquote>

<p>(40), (41)より</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
\hat\beta - \tilde\beta_{-i} &amp;= (X_{-i}'X_{-i})^{-1}X_i\hat e_i\\
&amp;= \left(\frac{\hat e_i}{1-h_{ii}}\right)(X'X)^{-1}X_i
\end{align*}\)</p>
</div>

<div style="text-align: right;">
  <p>■</p>
</div>

<p><strong>$\hat e_i$と$\tilde e_{i}$の関係</strong></p>

<p>(38)より</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
Y_i - X_i'\hat\beta &amp;= Y_i - X_i'(\tilde\beta_{-i} + (X'X_)^{-1}X_{i}\tilde e_i) \\
&amp;= \tilde e_i - h_{ii}\tilde e_i\\
&amp;= (1 - h_{ii})\tilde e_i\\
&amp;= \hat e_i
\end{align*}\)</p>
</div>

<p>これを踏まえるとLOOのprediction errorとOLS MSEの関係性は以下のように書けます.</p>

<div class="math display" style="overflow: auto">
  <p>\(\tilde \sigma^2 = \frac{1}{n}\sum \tilde e_i^2 = \frac{1}{n}\sum  (1 - h_{ii})^{-2}\hat e_i^2 \tag{42}\)</p>
</div>

<p>(42)の解釈としては</p>

<ul>
  <li>the prediction standard errorはすべてのサンプルを用いで学習するOLS standard error(ある種のtraining error)よりも大きい</li>
</ul>

<blockquote>
  <p>REMARKS</p>
</blockquote>

<ul>
  <li>OLS estimatorはinfluencial observationの影響を強く受ける推定量なので、training dataのoutlier detectionを実施する際に用いられることがある</li>
  <li>ただし、outlierを除外することは常に良いとは限らない（例：outlierが真のモデルに従っている場合など）</li>
</ul>

<h3 id="goodness-of-fit-measure">Goodness of fit measure</h3>

<p><strong>Estimation of Error Variance</strong></p>

\[\begin{align*}
y_i &amp;= x_i'\beta + e_i\\
E[e_i^2] &amp;= \sigma^2
\end{align*}\]

<p>というモデルに従ってデータが生成されたとします. このとき仮に$e_i$が観測されるならば, $\sigma^2$の推定量として</p>

\[\begin{align*}
\tilde\sigma^2 &amp;= \frac{1}{n}\sum_i e_i^2
&amp;= n^{-1}e'e\tag{43}
\end{align*}\]

<p>次に、$e_i$が観測されない場合は OLS residual $\hat e_i$を用いて以下のように推定します</p>

\[\begin{align*}
\hat\sigma^2 &amp;= \sum \hat e_i^2\\
&amp;= n^{-1}\hat e'\hat e\\
&amp;= n^{-1} e'M'Me\\
&amp;= n^{-1} e'Me \tag{44}
\end{align*}\]

<p>(43), (44)を比較すると</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
\tilde\sigma^2 - \hat\sigma^2  &amp;= n^{-1}(e'e - e'Me)\\
&amp; = n^{-1} ePe \geq 0 \tag{45}
\end{align*}\)</p>
</div>

<ul>
  <li>(45)は射影行列はpositive semi definiteより</li>
  <li>the feasible estimator $\hat \sigma^2$は数値的に理想的なestimatorよりも小さいことがわかる</li>
</ul>

<p><strong>Analysis of Variance</strong></p>

\[y_i = x_i'\beta + u_i\]

<p>というregression modelを考えます. $(x_i, u_i)$はuncorrelatedの場合</p>

\[\text{Var}(y_i) = \text{Var}(x_i'\beta)+\text{Var}(u_i) &gt; 0\quad\quad\tag{46}\]

<p>(46)を変形すると</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
\frac{\text{Var}(x_i'\beta)}{\text{Var}(y_i)}+\frac{\text{Var}(u_i)}{\text{Var}(y_i)}=1 \quad\quad\tag{47}
\end{align*}\)</p>
</div>

<ul>
  <li>$y_i$の変動は$x_i’\beta$で説明できる割合と$u_i$で説明できる割合に分けて考えることができることを(47)は示しています</li>
  <li>特に, $\text{Var}(x_i’\beta)/\text{Var}(y_i)$をGoodness of fit, $\mathbf R^2$ として一般的には用います</li>
</ul>

<p>次にこれをOLS estimatorの観点から考えてみます.</p>

\[Y = PY + MY = \hat Y + \hat e \quad\quad\tag{48}\]

<p>(48)から $\mathbf 1_n \bar Y$を引くと</p>

\[Y - \mathbf 1_n \bar Y = \hat Y - \mathbf 1_n \bar Y + \hat e \quad\quad\tag{49}\]

<p>Then,</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
(Y - \mathbf 1_n \bar Y )'(Y - \mathbf 1_n \bar Y ) &amp;= (Y - \mathbf 1_n \bar Y )'(\hat Y - \mathbf 1_n \bar Y) + (Y - \mathbf 1_n \bar Y )'\hat e\\
&amp;= (\hat Y - \mathbf 1_n \bar Y )'(\hat Y - \mathbf 1_n \bar Y) + \hat e'\hat e \quad\quad\tag{50}
\end{align*}\)</p>
</div>

<p>よって、</p>

\[\mathbf R^2 = \frac{\sum (\hat Y_i - \bar Y)^2}{\sum (Y_i - \bar Y)^2} = 1 - \frac{\sum e_i^2}{\sum (Y_i - \bar Y)^2} \quad\quad\tag{51}\]

<p><strong>$R^2$の解釈の留意点</strong></p>

<ul>
  <li>Econometricsにおける分析の主眼点はtreament effectのパラメーターをconsistentに推定することであって、$R^2$の数値の高さ自体はあくまでa secondary importance</li>
  <li>$R^2$の数値はregressorを加えれば加えるほど高くなる性質があり、regressorsの選択がtrue modelに基づいているか否かの情報は提供してくれない</li>
  <li>regressorを加えれば加えるほど、the residualの推定の自由度が下がるため、$R^2$の数値の数値のぶれが大きくなる</li>
  <li>causal modelの評価には有用ではない</li>
</ul>

<p>二点目の性質に対処したスコアとしてAdjusted R-squaredという評価スコアがあります</p>

\[\text{Adj-}R^2 = 1 - \frac{(N - K)^{-1}\sum \hat u_i^2}{(N - 1)^{-1} \sum (Y_i - \bar Y)^2}\]

<ul>
  <li>K: the number of regressors including the constant term</li>
  <li>TSSとSSRをそれぞれの自由度で除したものを計算し、それらの比率をもってGoodness of fitを計算しようというモチベーション</li>
</ul>

<h4 id="regressorとr-squaredの関係">RegressorとR-squaredの関係</h4>

<p>$R^2$の数値はregressorを加えれば加えるほど高くなることを確認します.</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
Y &amp;= X\beta + u \quad\quad\tag{52} \\
Y &amp;= X\beta_0 + X_1\beta_1 + v \quad\quad\tag{53}
\end{align*}\)</p>
</div>

<p>という２つのOLS regression modelを考えます. (52), (53)を合わせると</p>

\[X\beta + u = X\beta_0 + X_1\beta_1 + v\]

<p>OLS regresionのresidualの性質より</p>

\[\begin{align*}
u'u &amp;= u'X_1\beta_1 + u'v \quad\quad\tag{54}\\
v'u &amp;= v'v \quad\quad\tag{55}
\end{align*}\]

<p>(54), (55)から次式を得ます</p>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
v'v &amp;= (y - X\beta_0 - X_1\beta_1)'(y - X\beta_0 - X_1\beta_1)\\
&amp;= (X\beta + u - X\beta_0 - X_1\beta_1)'(X\beta + u - X\beta_0 - X_1\beta_1)\\
&amp;= (u+ X(\beta - \beta_0) - X_1\beta_1)'(u+ X(\beta - \beta_0) - X_1\beta_1)\\
&amp;= (X(\beta - \beta_0) - X_1\beta_1)'(X(\beta - \beta_0) - X_1\beta_1) + u'u - 2u'X_1\beta_1\\
&amp;= (X(\beta - \beta_0) - X_1\beta_1)'(X(\beta - \beta_0) - X_1\beta_1) + u'u - 2(u'u - v'v)\\
&amp;= (X(\beta - \beta_0) - X_1\beta_1)'(X(\beta - \beta_0) - X_1\beta_1) + 2v'v - u'u\\
&amp;\Rightarrow u'u = (X(\beta - \beta_0) - X_1\beta_1)'(X(\beta - \beta_0) - X_1\beta_1) + v'v \quad\quad\tag{56}
\end{align*}\)</p>
</div>

<p>(56)における$(X(\beta - \beta_0) - X_1\beta_1)’(X(\beta - \beta_0) - X_1\beta_1) \geq 0$より</p>

\[u'u \geq v'v\]

<div style="text-align: right;">
  <p>■</p>
</div>

<h2 id="3-property-of-ols-estimator">3. Property of OLS Estimator</h2>
<h3 id="assumptions">Assumptions</h3>

<div class="math display" style="overflow: auto">

  <p><strong>Assumption 1: mutually independent and identical distribution</strong></p>

  <p>The random variable ${(Y_1, X_1), \cdots, (Y_i, X_i), \cdots, (Y_N, X_N)}$ are i.i.d</p>

  <ul>
    <li>$i\neq j$のとき、$(Y_i, X_i)$は$(Y_j, X_j)$とは独立だが、同じ分布に従っているという意味</li>
    <li>iさんの意思決定がjさんのoutcomeに影響しない (and conversely)との解釈できる</li>
  </ul>

  <p><strong>Assumption 2: Linear Regression Model</strong></p>

  <p>The variable $(Y_i, X_i)$は以下のLinear Regression Modelを満たす</p>

\[\begin{align*}
\mathbf Y &amp;= \mathbf X\beta + \epsilon\\
E[\epsilon|\mathbf X] &amp;= 0
\end{align*}\]

  <p><strong>Assumption 3: The finite second moments</strong></p>

\[\begin{align*}
E[Y_i^2] &amp;&lt; \infty\\
E[\|X_i^2\|] &amp;&lt; \infty
\end{align*}\]

  <p><strong>Assumption 4-1: The full rank</strong></p>

  <p>$X_i \in \mathbf R^k$としたとき、</p>

\[\text{rank}(X_i) = k\]

  <ul>
    <li>Perfect Multicollinearityが存在しない</li>
    <li>$\mathbf X’\mathbf X$がinvertibleと同値</li>
  </ul>

  <p><strong>Assumption 4-2: The invertible assumption</strong></p>

\[\begin{align*}
Q_{XX} = E[\mathbf X'\mathbf X] &gt; 0
\end{align*}\]

  <p>としたとき、$Q_{XX}^{-1}$が存在する.</p>

  <p><strong>Assumption 5: Homoskedasticity and nonautocorrelation</strong></p>

  <p>\(E[\epsilon\epsilon'|\mathbf X] = \sigma^2 \mathbf I_N\)</p>
</div>

<h3 id="unbiasedness">Unbiasedness</h3>

<blockquote>
  <p>Proof (1)</p>
</blockquote>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
E[\hat\beta|\mathbf X] &amp;= E[(X'X)^{-1}X'Y|X]\\
&amp;= \left(X'X\right)^{-1}E[X'Y|X]\\
&amp;= \left(\sum X_iX_i'\right)^{-1}E[\sum X_i Y_i|X]\\
&amp;= \left(\sum X_iX_i'\right)^{-1}(\sum X_i E[Y_i|X])\\
&amp;= \left(\sum X_iX_i'\right)^{-1}(\sum X_i X_i'\beta)\\
&amp;= \beta
\end{align*}\)</p>
</div>

<div style="text-align: right;">
  <p>■</p>
</div>

<blockquote>
  <p>Proof (2)</p>
</blockquote>

<div class="math display" style="overflow: auto">
  <p>\(\begin{align*}
E[\hat\beta - \beta|X]&amp;= E[(X'X)^{-1}(X'(X\beta + \epsilon) - \beta|X]\\
&amp;= E[\beta + (X'X)^{-1}(X'\epsilon) - \beta|X]\\
&amp;= E[(X'X)^{-1}(X'\epsilon)|X]\\
&amp;= (X'X)^{-1}(X'E[\epsilon|X])\\
&amp;= 0
\end{align*}\)</p>
</div>

<div style="text-align: right;">
  <p>■</p>
</div>
<div class="math display" style="overflow: auto">

  <h3 id="conditional-variance-of-ols-estimator">Conditional Variance of OLS estimator</h3>

\[\begin{align*}
Var(\hat\beta|X)&amp; = E[(X'X)^{-1}X'\epsilon\epsilon'X(X'X)^{-1}|X]\\
&amp;= (X'X)^{-1}X'E[\epsilon\epsilon'|X]X(X'X)^{-1}\\
&amp;= \sigma^2(X'X)^{-1}
\end{align*}\]

  <blockquote>
    <p>Unconditional Variance</p>
  </blockquote>

\[\begin{align*}
Var(\hat\beta) &amp;= E[Var(\hat\beta|X)] + Var(E[\hat\beta|X])\\
&amp;= E[\sigma^2(X'X)^{-1}] + Var(\beta)\\
&amp;= \sigma^2E[(X'X)^{-1}]
\end{align*}\]

  <h3 id="gauss-markov-theorem">Gauss-Markov Theorem</h3>

  <p>Assumption (1) ~ (5)のもとで</p>

\[\begin{align*}
\tilde \beta &amp;= C'Y \quad\quad\tag{3-1}\\
E[\tilde \beta|X] &amp;= \beta \quad\quad\tag{3-2}
\end{align*}\]

  <p>というLinear estimator classを考えます. このとき、</p>

\[Var(\tilde \beta|X) \geq \sigma^2(X'X)^{-1}\quad\quad\tag{3-3}\]

  <p>が成立します。この定理のことをGauss-Markov Theoremといいます.</p>

  <blockquote>
    <p>Proof</p>
  </blockquote>

  <p>$Var(\tilde \beta|X) = \sigma^2C’C$より $C’C - (X’X)^{-1} \geq 0$が示せれば十分です.</p>

  <p>(3-2)より $C’X = I_k$が得られるので、</p>

\[\begin{align*}
D&amp;\equiv C - X(X'X)^{-1} \quad\quad\tag{3-4}\\
D'X&amp; = 0 \quad\quad\tag{3-5}
\end{align*}\]

  <p>\(\begin{align*}
C'C - (X'X)^{-1} &amp;= (D + X(X'X)^{-1})'(D + X(X'X)^{-1}) - (X'X)^{-1}\\
&amp;= D'D + (X'X)^{-1}X'X(X'X)^{-1}- (X'X)^{-1}\\
&amp;= D'D
\end{align*}\)</p>
</div>

<p>$D’D$は$d = Da$とすると、任意の0でないベクトル$a$について、$d’d \geq 0$が成立するので、$D’D \geq 0$</p>

<div style="text-align: right;">
  <p>■</p>
</div>

<h2 id="4-asymptotic-property-of-ols-estimator">4. Asymptotic Property of OLS Estimator</h2>


                <hr style="visibility: hidden;">
                <hr/>
                <b><fontsize="5">Share Buttons</font><br></b>
                <!--see 
    https://jekyllcodex.org/without-plugin/share-buttons/ 
    https://ranvir.xyz/blog/why-and-how-to-add-social-sharing-buttons-on-your-jekyll-blog-using-github-pages/
-->



<style>
#share-buttons {display: inline-block; vertical-align: middle; }
#share-buttons:after {content: ""; display: block; clear: both;}
#share-buttons > div {
    position: relative;
    text-align: left; 
    height: 36px; 
    width: 32px; 
    float: left; 
    text-align: center;
}
#share-buttons > div > svg {height: 16px; fill: #d5d5d5; margin-top: 10px;}
#share-buttons > div:hover {cursor: pointer;}
#share-buttons > div.facebook:hover > svg {fill: #3B5998;}
#share-buttons > div.twitter:hover > svg {fill: #55ACEE;}
#share-buttons > div.linkedin:hover > svg {fill: #0077b5;}
#share-buttons > div.pinterest:hover > svg {fill: #CB2027;}
#share-buttons > div.gplus:hover > svg {fill: #dd4b39;}
#share-buttons > div.mail:hover > svg {fill: #7D7D7D;}
#share-buttons > div.instagram:hover > svg {fill: #C73B92;}
#share-buttons > div.facebook > svg {height: 18px; margin-top: 9px;}
#share-buttons > div.twitter > svg {height: 20px; margin-top: 8px;}
#share-buttons > div.linkedin > svg {height: 19px; margin-top: 7px;}
#share-buttons > div.pinterest > svg {height: 20px; margin-top: 9px;}
#share-buttons > div.gplus > svg {height: 17px; margin-top: 9px; position: relative; left: 1px;}
#share-buttons > div.mail > svg {height: 14px; margin-top: 11px;}
</style>

<span style="color: black">Share on: </span><div id="share-buttons">
    <div class="facebook" title="Share this on Facebook" onclick="gtag('event', 'Facebook', {'event_category':'Post Shared','event_label':'Facebook'}); location.href='http://www.facebook.com/share.php?u=https://ryonakagami.github.io/2021/11/01/Econometrics101-01-LinearRegression/';"><svg viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M1343 12v264h-157q-86 0-116 36t-30 108v189h293l-39 296h-254v759h-306v-759h-255v-296h255v-218q0-186 104-288.5t277-102.5q147 0 228 12z"/></svg></div>
    <div class="twitter" title="Share this on Twitter" onclick="gtag('event', 'Twitter', {'event_category':'Post Shared','event_label':'Twitter'}); location.href='https://twitter.com/intent/tweet?text=Econometrics101 - 復習&url=https://ryonakagami.github.io/2021/11/01/Econometrics101-01-LinearRegression/';"><svg viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M1684 408q-67 98-162 167 1 14 1 42 0 130-38 259.5t-115.5 248.5-184.5 210.5-258 146-323 54.5q-271 0-496-145 35 4 78 4 225 0 401-138-105-2-188-64.5t-114-159.5q33 5 61 5 43 0 85-11-112-23-185.5-111.5t-73.5-205.5v-4q68 38 146 41-66-44-105-115t-39-154q0-88 44-163 121 149 294.5 238.5t371.5 99.5q-8-38-8-74 0-134 94.5-228.5t228.5-94.5q140 0 236 102 109-21 205-78-37 115-142 178 93-10 186-50z"/></svg></div>
    <div class="linkedin" title="Share this on Linkedin" onclick="gtag('event', 'Linkedin', {'event_category':'Post Shared','event_label':'Linkedin'}); location.href='https://www.linkedin.com/shareArticle?mini=true&url=https://ryonakagami.github.io/2021/11/01/Econometrics101-01-LinearRegression/&title=&summary=&source=';"><svg viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M477 625v991h-330v-991h330zm21-306q1 73-50.5 122t-135.5 49h-2q-82 0-132-49t-50-122q0-74 51.5-122.5t134.5-48.5 133 48.5 51 122.5zm1166 729v568h-329v-530q0-105-40.5-164.5t-126.5-59.5q-63 0-105.5 34.5t-63.5 85.5q-11 30-11 81v553h-329q2-399 2-647t-1-296l-1-48h329v144h-2q20-32 41-56t56.5-52 87-43.5 114.5-15.5q171 0 275 113.5t104 332.5z"/></svg></div>
    
    <div class="mail" title="Share this through Email" onclick="gtag('event', 'Email', {'event_category':'Post Shared','event_label':'Email'}); location.href='mailto:?&body=https://ryonakagami.github.io/2021/11/01/Econometrics101-01-LinearRegression/';"><svg viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M1792 710v794q0 66-47 113t-113 47h-1472q-66 0-113-47t-47-113v-794q44 49 101 87 362 246 497 345 57 42 92.5 65.5t94.5 48 110 24.5h2q51 0 110-24.5t94.5-48 92.5-65.5q170-123 498-345 57-39 100-87zm0-294q0 79-49 151t-122 123q-376 261-468 325-10 7-42.5 30.5t-54 38-52 32.5-57.5 27-50 9h-2q-23 0-50-9t-57.5-27-52-32.5-54-38-42.5-30.5q-91-64-262-182.5t-205-142.5q-62-42-117-115.5t-55-136.5q0-78 41.5-130t118.5-52h1472q65 0 112.5 47t47.5 113z"/></svg></div>
</div>

                
                <hr/>

                <!-- Featured Tags -->
                <b><fontsize="5">Feature Tags</b>
                    <div id="tag_cloud" class="tags tags-sup js-tags" 
                    style="line-height: 0px !important;">
                        
                        
                        
                        
                        
                                <a data-sort="0288" 
                                    href="/archive/?tag=%E7%B5%B1%E8%A8%88"
                                    title="統計"
                                    style="color: #337ab7 !important;"
                                    rel="61">統計</a>
                        
                                <a data-sort="0298" 
                                    href="/archive/?tag=Python"
                                    title="Python"
                                    style="color: #337ab7 !important;"
                                    rel="51">Python</a>
                        
                                <a data-sort="0300" 
                                    href="/archive/?tag=math"
                                    title="math"
                                    style="color: #337ab7 !important;"
                                    rel="49">math</a>
                        
                                <a data-sort="0303" 
                                    href="/archive/?tag=Linux"
                                    title="Linux"
                                    style="color: #337ab7 !important;"
                                    rel="46">Linux</a>
                        
                                <a data-sort="0316" 
                                    href="/archive/?tag=Ubuntu+20.04+LTS"
                                    title="Ubuntu 20.04 LTS"
                                    style="color: #337ab7 !important;"
                                    rel="33">Ubuntu 20.04 LTS</a>
                        
                                <a data-sort="0319" 
                                    href="/archive/?tag=Shell"
                                    title="Shell"
                                    style="color: #337ab7 !important;"
                                    rel="30">Shell</a>
                        
                                <a data-sort="0321" 
                                    href="/archive/?tag=English"
                                    title="English"
                                    style="color: #337ab7 !important;"
                                    rel="28">English</a>
                        
                                <a data-sort="0324" 
                                    href="/archive/?tag=git"
                                    title="git"
                                    style="color: #337ab7 !important;"
                                    rel="25">git</a>
                        
                                <a data-sort="0329" 
                                    href="/archive/?tag=%E6%96%B9%E6%B3%95%E8%AB%96"
                                    title="方法論"
                                    style="color: #337ab7 !important;"
                                    rel="20">方法論</a>
                        
                                <a data-sort="0333" 
                                    href="/archive/?tag=Ubuntu+22.04+LTS"
                                    title="Ubuntu 22.04 LTS"
                                    style="color: #337ab7 !important;"
                                    rel="16">Ubuntu 22.04 LTS</a>
                        
                                <a data-sort="0337" 
                                    href="/archive/?tag=%E7%B5%B1%E8%A8%88%E6%A4%9C%E5%AE%9A"
                                    title="統計検定"
                                    style="color: #337ab7 !important;"
                                    rel="12">統計検定</a>
                        
                                <a data-sort="0338" 
                                    href="/archive/?tag=%E7%AB%B6%E6%8A%80%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0"
                                    title="競技プログラミング"
                                    style="color: #337ab7 !important;"
                                    rel="11">競技プログラミング</a>
                        
                                <a data-sort="0339" 
                                    href="/archive/?tag=%E3%83%95%E3%83%BC%E3%83%AA%E3%82%A8%E8%A7%A3%E6%9E%90"
                                    title="フーリエ解析"
                                    style="color: #337ab7 !important;"
                                    rel="10">フーリエ解析</a>
                        
                                <a data-sort="0340" 
                                    href="/archive/?tag=%E5%89%8D%E5%87%A6%E7%90%86"
                                    title="前処理"
                                    style="color: #337ab7 !important;"
                                    rel="9">前処理</a>
                        
                                <a data-sort="0340" 
                                    href="/archive/?tag=SQL"
                                    title="SQL"
                                    style="color: #337ab7 !important;"
                                    rel="9">SQL</a>
                        
                                <a data-sort="0340" 
                                    href="/archive/?tag=coding"
                                    title="coding"
                                    style="color: #337ab7 !important;"
                                    rel="9">coding</a>
                        
                                <a data-sort="0341" 
                                    href="/archive/?tag=%E3%82%B3%E3%83%9F%E3%83%A5%E3%83%8B%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3"
                                    title="コミュニケーション"
                                    style="color: #337ab7 !important;"
                                    rel="8">コミュニケーション</a>
                        
                                <a data-sort="0342" 
                                    href="/archive/?tag=Network"
                                    title="Network"
                                    style="color: #337ab7 !important;"
                                    rel="7">Network</a>
                        
                                <a data-sort="0342" 
                                    href="/archive/?tag=ssh"
                                    title="ssh"
                                    style="color: #337ab7 !important;"
                                    rel="7">ssh</a>
                        
                                <a data-sort="0343" 
                                    href="/archive/?tag=%E5%B0%86%E6%A3%8B"
                                    title="将棋"
                                    style="color: #337ab7 !important;"
                                    rel="6">将棋</a>
                        
                                <a data-sort="0343" 
                                    href="/archive/?tag=Data+visualization"
                                    title="Data visualization"
                                    style="color: #337ab7 !important;"
                                    rel="6">Data visualization</a>
                        
                                <a data-sort="0343" 
                                    href="/archive/?tag=Docker"
                                    title="Docker"
                                    style="color: #337ab7 !important;"
                                    rel="6">Docker</a>
                        
                                <a data-sort="0343" 
                                    href="/archive/?tag=Econometrics"
                                    title="Econometrics"
                                    style="color: #337ab7 !important;"
                                    rel="6">Econometrics</a>
                        
                                <a data-sort="0343" 
                                    href="/archive/?tag=VSCode"
                                    title="VSCode"
                                    style="color: #337ab7 !important;"
                                    rel="6">VSCode</a>
                        
                                <a data-sort="0343" 
                                    href="/archive/?tag=statistical+inference"
                                    title="statistical inference"
                                    style="color: #337ab7 !important;"
                                    rel="6">statistical inference</a>
                        
                                <a data-sort="0344" 
                                    href="/archive/?tag=GitHub+Pages"
                                    title="GitHub Pages"
                                    style="color: #337ab7 !important;"
                                    rel="5">GitHub Pages</a>
                        
                                <a data-sort="0344" 
                                    href="/archive/?tag=apt"
                                    title="apt"
                                    style="color: #337ab7 !important;"
                                    rel="5">apt</a>
                        
                                <a data-sort="0344" 
                                    href="/archive/?tag=development"
                                    title="development"
                                    style="color: #337ab7 !important;"
                                    rel="5">development</a>
                        
                                <a data-sort="0345" 
                                    href="/archive/?tag=%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E7%AE%A1%E7%90%86"
                                    title="システム管理"
                                    style="color: #337ab7 !important;"
                                    rel="4">システム管理</a>
                        
                                <a data-sort="0345" 
                                    href="/archive/?tag=Coffee"
                                    title="Coffee"
                                    style="color: #337ab7 !important;"
                                    rel="4">Coffee</a>
                        
                                <a data-sort="0345" 
                                    href="/archive/?tag=cloud"
                                    title="cloud"
                                    style="color: #337ab7 !important;"
                                    rel="4">cloud</a>
                        
                                <a data-sort="0346" 
                                    href="/archive/?tag=%E6%95%B0%E5%80%A4%E8%A8%88%E7%AE%97"
                                    title="数値計算"
                                    style="color: #337ab7 !important;"
                                    rel="3">数値計算</a>
                        
                                <a data-sort="0346" 
                                    href="/archive/?tag=%E7%B4%A0%E6%95%B0"
                                    title="素数"
                                    style="color: #337ab7 !important;"
                                    rel="3">素数</a>
                        
                                <a data-sort="0346" 
                                    href="/archive/?tag=Book"
                                    title="Book"
                                    style="color: #337ab7 !important;"
                                    rel="3">Book</a>
                        
                                <a data-sort="0346" 
                                    href="/archive/?tag=Font"
                                    title="Font"
                                    style="color: #337ab7 !important;"
                                    rel="3">Font</a>
                        
                                <a data-sort="0346" 
                                    href="/archive/?tag=Metrics"
                                    title="Metrics"
                                    style="color: #337ab7 !important;"
                                    rel="3">Metrics</a>
                        
                                <a data-sort="0346" 
                                    href="/archive/?tag=Poetry"
                                    title="Poetry"
                                    style="color: #337ab7 !important;"
                                    rel="3">Poetry</a>
                        
                                <a data-sort="0346" 
                                    href="/archive/?tag=Ubuntu+24.04+LTS"
                                    title="Ubuntu 24.04 LTS"
                                    style="color: #337ab7 !important;"
                                    rel="3">Ubuntu 24.04 LTS</a>
                        
                                <a data-sort="0346" 
                                    href="/archive/?tag=architecture"
                                    title="architecture"
                                    style="color: #337ab7 !important;"
                                    rel="3">architecture</a>
                        
                                <a data-sort="0346" 
                                    href="/archive/?tag=aws"
                                    title="aws"
                                    style="color: #337ab7 !important;"
                                    rel="3">aws</a>
                        
                                <a data-sort="0346" 
                                    href="/archive/?tag=shell"
                                    title="shell"
                                    style="color: #337ab7 !important;"
                                    rel="3">shell</a>
                        
                                <a data-sort="0346" 
                                    href="/archive/?tag=systemctl"
                                    title="systemctl"
                                    style="color: #337ab7 !important;"
                                    rel="3">systemctl</a>
                        
                                <a data-sort="0347" 
                                    href="/archive/?tag=%E3%83%86%E3%83%B3%E3%83%97%E3%83%AC%E3%83%BC%E3%83%88"
                                    title="テンプレート"
                                    style="color: #337ab7 !important;"
                                    rel="2">テンプレート</a>
                        
                                <a data-sort="0347" 
                                    href="/archive/?tag=%E3%83%87%E3%83%BC%E3%82%BF%E6%A7%8B%E9%80%A0"
                                    title="データ構造"
                                    style="color: #337ab7 !important;"
                                    rel="2">データ構造</a>
                        
                                <a data-sort="0347" 
                                    href="/archive/?tag=%E3%83%9D%E3%83%AF%E3%82%BD%E3%83%B3%E5%88%86%E5%B8%83"
                                    title="ポワソン分布"
                                    style="color: #337ab7 !important;"
                                    rel="2">ポワソン分布</a>
                        
                                <a data-sort="0347" 
                                    href="/archive/?tag=%E4%BC%9A%E8%A8%88%E5%88%86%E6%9E%90"
                                    title="会計分析"
                                    style="color: #337ab7 !important;"
                                    rel="2">会計分析</a>
                        
                                <a data-sort="0347" 
                                    href="/archive/?tag=%E6%96%87%E5%AD%97%E3%82%B3%E3%83%BC%E3%83%89"
                                    title="文字コード"
                                    style="color: #337ab7 !important;"
                                    rel="2">文字コード</a>
                        
                                <a data-sort="0347" 
                                    href="/archive/?tag=%E7%92%B0%E5%A2%83%E6%A7%8B%E7%AF%89"
                                    title="環境構築"
                                    style="color: #337ab7 !important;"
                                    rel="2">環境構築</a>
                        
                                <a data-sort="0347" 
                                    href="/archive/?tag=%E8%AB%96%E6%96%87"
                                    title="論文"
                                    style="color: #337ab7 !important;"
                                    rel="2">論文</a>
                        
                                <a data-sort="0347" 
                                    href="/archive/?tag=App"
                                    title="App"
                                    style="color: #337ab7 !important;"
                                    rel="2">App</a>
                        
                                <a data-sort="0347" 
                                    href="/archive/?tag=Bayesian"
                                    title="Bayesian"
                                    style="color: #337ab7 !important;"
                                    rel="2">Bayesian</a>
                        
                                <a data-sort="0347" 
                                    href="/archive/?tag=Dynamic+Programming"
                                    title="Dynamic Programming"
                                    style="color: #337ab7 !important;"
                                    rel="2">Dynamic Programming</a>
                        
                                <a data-sort="0347" 
                                    href="/archive/?tag=Keyboard"
                                    title="Keyboard"
                                    style="color: #337ab7 !important;"
                                    rel="2">Keyboard</a>
                        
                                <a data-sort="0347" 
                                    href="/archive/?tag=Processing"
                                    title="Processing"
                                    style="color: #337ab7 !important;"
                                    rel="2">Processing</a>
                        
                                <a data-sort="0347" 
                                    href="/archive/?tag=R"
                                    title="R"
                                    style="color: #337ab7 !important;"
                                    rel="2">R</a>
                        
                                <a data-sort="0347" 
                                    href="/archive/?tag=Steam"
                                    title="Steam"
                                    style="color: #337ab7 !important;"
                                    rel="2">Steam</a>
                        
                                <a data-sort="0347" 
                                    href="/archive/?tag=filesystem"
                                    title="filesystem"
                                    style="color: #337ab7 !important;"
                                    rel="2">filesystem</a>
                        
                                <a data-sort="0347" 
                                    href="/archive/?tag=quarto"
                                    title="quarto"
                                    style="color: #337ab7 !important;"
                                    rel="2">quarto</a>
                        
                                <a data-sort="0347" 
                                    href="/archive/?tag=regex"
                                    title="regex"
                                    style="color: #337ab7 !important;"
                                    rel="2">regex</a>
                    </div>

                <br>

                <b><fontsize="5">Leave a Comment</font><br>(注意：GitHub Accountが必要となります）</b>
                
                <script src="https://utteranc.es/client.js"
                    repo="RyoNakagami/RyoNakagami.github.io"
                    issue-term="url"
                    theme="github-light"
                    crossorigin="anonymous"
                    async>Reduce unused JavaScript
                
                </script>


            </div>  

    <!-- Side Catalog Container -->
        
            <div class="
                col-lg-1 col-lg-offset-0
                visible-lg-block
                sidebar-container
                catalog-container">
                <div class="side-catalog fixed" style="margin-top:3%">
                    <hr class="hidden-sm hidden-xs">
                    <h5>
                        <a class="catalog-toggle" href="#">CONTENTS</a>
                    </h5>
                    <ul class="catalog-body"></ul>
                </div>
            </div>
        
    <!-- Sidebar Container -->
            <!-- <div class="
                col-lg-10 col-lg-offset-1
                col-md-10 col-md-offset-1
                sidebar-container row"> -->
                <!-- 
<hr>
<h5>FRIENDS</h5>
<ul class="list-inline">
  
  <li><a href="https://twitter.com/bluesky0804?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor">bluesky0804</a></li>
  
</ul>

 -->
            </div>
        </div>
    </div>
</article>

<!-- add support for mathjax by voleking-->

  <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" id="MathJax-script"></script>
<script>
  MathJax = {
    tex: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      displayMath: [['$$','$$'], ['\\[','\\]']],
      processEscapes: true,
      processEnvironments: true, // for pseudo
      tags: "ams",
      autoload: {
        color: [],
        colorV2: ['color']
      },
      packages: {'[+]': ['noerrors']}
    },
    chtml: {
      matchFontHeight: false,
      displayAlign: "left",
      displayIndent: "2em"
    },
    options: {
      renderActions: {
        /* add a new named action to render <script type="math/tex"> */
        find_script_mathtex: [10, function (doc) {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/);
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
            const text = document.createTextNode('');
            node.parentNode.replaceChild(text, node);
            math.start = {node: text, delim: '', n: 0};
            math.end = {node: text, delim: '', n: 0};
            doc.math.push(math);
          }
        }, '']
      }
    },
    loader: {
      load: ['[tex]/noerrors']
    }
  };
</script>





<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'hover',
          placement: 'right',
          // icon: '#'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>


<body>
    <!-- enable mermaid language on markdown post -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.6.1/mermaid.min.js"></script>
<script>
   mermaid.initialize({
       startOnLoad:true,
       theme: 'default'
   });
   window.mermaid.init(undefined, document.querySelectorAll('.language-mermaid'));
</script>

</body>

    <script>
    
    var elements = document.querySelectorAll('p');
    Array.prototype.forEach.call(elements, function(el, i){
        if(el.innerHTML=='[expand]') {
            var parentcontent = el.parentNode.innerHTML.replace('<p>[expand]</p>','<div class="expand" style="display: none; height: 0; overflow: hidden;">').replace('<p>[/expand]</p>','</div>');
            el.parentNode.innerHTML = parentcontent;
        }
    });

    var elements = document.querySelectorAll('div.expand');
    Array.prototype.forEach.call(elements, function(el, i){
        el.previousElementSibling.innerHTML = el.previousElementSibling.innerHTML + '<span>..&nbsp; <a href="#" style="cursor: pointer;" onclick="this.parentNode.parentNode.nextElementSibling.style.display = \'block\'; this.parentNode.parentNode.nextElementSibling.style.height = \'auto\'; this.parentNode.style.display = \'none\';">read&nbsp;more&nbsp;&rarr;</a></span>';
    });

</script>

    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <!--<div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"> -->
                <!-- SNS Link -->
            


<ul class="list-inline text-center">


  
  
  
  
  <li>
    <a target="_blank" href="https://github.com/RyoNakagami">
      <span class="fa-stack fa-lg">
        <i class="fa fa-circle fa-stack-2x"></i>
        <i class="fa fa-github fa-stack-1x fa-inverse"></i>
      </span>
    </a>
  </li>
  
  
</ul>

            
            <p class="copyright text-muted">
                Copyright &copy; Ryo's Tech Blog 2025
                <br>
                Powered by <a href="https://ryonakagami.github.io">Ryo's Tech Blog</a> |
                <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="100px"
                    height="20px"
                    title="RyoNakagami.github.io github stars"
                    src="https://ghbtns.com/github-btn.html?user=RyoNakagami&repo=RyoNakagami.github.io&type=star&count=true">
                </iframe>
            </p>
            <!--</div> -->
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<!-- Currently, only navbar scroll-down effect at desktop still depends on this -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/ryo-blog.min.js "></script>

<!-- Simple Jekyll Search -->
<script src="/js/simple-jekyll-search.min.js"></script>

<!-- Service Worker -->

<script src="/js/snackbar.js "></script>
<script src="/js/sw-registration.js "></script>


<!-- async load function -->
<script>
    function async(u, c) {
        var d = document, t = 'script',
            o = d.createElement(t),
            s = d.getElementsByTagName(t)[0];
        o.src = u;
        if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
        s.parentNode.insertBefore(o, s);
    }
</script>

<!--
     Because of the native support for backtick-style fenced code blocks
     right within the Markdown is landed in Github Pages,
     From V1.6, There is no need for Highlight.js,
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/
     - https://github.com/jneen/rouge/wiki/list-of-supported-languages-and-lexers
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->







<!--fastClick.js -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function () {
        var $nav = document.querySelector("nav");
        if ($nav) FastClick.attach($nav);
    })
</script>


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-LVL413SV09"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-LVL413SV09');
</script>



<!-- Side Catalog -->

<script type="text/javascript">
    function generateCatalog(selector) {

        // interop with multilangual 
        if ('' == 'true') {
            _containerSelector = 'div.post-container.active'
        } else {
            _containerSelector = 'div.post-container'
        }

        // init
        var P = $(_containerSelector), a, n, t, l, i, c;
        a = P.find('h1,h2,h3,h4,h5,h6');

        // clean
        $(selector).html('')

        // appending
        a.each(function () {
            n = $(this).prop('tagName').toLowerCase();
            i = "#" + $(this).prop('id');
            t = $(this).text();
            c = $('<a href="' + i + '" rel="nofollow">' + t + '</a>');
            l = $('<li class="' + n + '_nav"></li>').append(c);
            $(selector).append(l);
        });
        return true;
    }

    generateCatalog(".catalog-body");

    // toggle side catalog
    $(".catalog-toggle").click((function (e) {
        e.preventDefault();
        $('.side-catalog').toggleClass("fold")
    }))

    /*
     * Doc: https://github.com/davist11/jQuery-One-Page-Nav
     * Fork by Hux to support padding
     */
    async("/js/jquery.nav.js", function () {
        $('.catalog-body').onePageNav({
            currentClass: "active",
            changeHash: !1,
            easing: "swing",
            filter: "",
            scrollSpeed: 700,
            scrollOffset: 0,
            scrollThreshold: .2,
            begin: null,
            end: null,
            scrollChange: null,
            padding: 80
        });
    });
</script>



<!-- Multi-Lingual -->


<!-- Simple Jekyll Search -->
<script>
    // https://stackoverflow.com/questions/1912501/unescape-html-entities-in-javascript
    function htmlDecode(input) {
        var e = document.createElement('textarea');
        e.innerHTML = input;
        // handle case of empty input
        return e.childNodes.length === 0 ? "" : e.childNodes[0].nodeValue;
    }

    SimpleJekyllSearch({
        searchInput: document.getElementById('search-input'),
        resultsContainer: document.getElementById('search-results'),
        json: '/search.json',
        searchResultTemplate: '<div class="post-preview item"><a href="{url}"><h2 class="post-title">{title}</h2><h3 class="post-subtitle">{subtitle}</h3><hr></a></div>',
        noResultsText: 'No results',
        limit: 50,
        fuzzy: false,
        // a hack to get escaped subtitle unescaped. for some reason, 
        // post.subtitle w/o escape filter nuke entire search.
        templateMiddleware: function (prop, value, template) {
            if (prop === 'subtitle' || prop === 'title') {
                if (value.indexOf("code")) {
                    return htmlDecode(value);
                } else {
                    return value;
                }
            }
        }
    });

    $(document).ready(function () {
        var $searchPage = $('.search-page');
        var $searchOpen = $('.search-icon');
        var $searchClose = $('.search-icon-close');
        var $searchInput = $('#search-input');
        var $body = $('body');

        $searchOpen.on('click', function (e) {
            e.preventDefault();
            $searchPage.toggleClass('search-active');
            var prevClasses = $body.attr('class') || '';
            setTimeout(function () {
                $body.addClass('no-scroll');
            }, 400)

            if ($searchPage.hasClass('search-active')) {
                $searchClose.on('click', function (e) {
                    e.preventDefault();
                    $searchPage.removeClass('search-active');
                    $body.attr('class', prevClasses);  // from closure 
                });
                $searchInput.focus();
            }
        });
    });
</script>



<!-- Image to Github 
<img src="/img/icon_wechat.png" width="0" height="0" />
<-- Migrate from head to bottom, no longer block render and still work -->
<script>
    
    var elements = document.querySelectorAll('p');
    Array.prototype.forEach.call(elements, function(el, i){
        if(el.innerHTML=='[expand]') {
            var parentcontent = el.parentNode.innerHTML.replace('<p>[expand]</p>','<div class="expand" style="display: none; height: 0; overflow: hidden;">').replace('<p>[/expand]</p>','</div>');
            el.parentNode.innerHTML = parentcontent;
        }
    });

    var elements = document.querySelectorAll('div.expand');
    Array.prototype.forEach.call(elements, function(el, i){
        el.previousElementSibling.innerHTML = el.previousElementSibling.innerHTML + '<span>..&nbsp; <a href="#" style="cursor: pointer;" onclick="this.parentNode.parentNode.nextElementSibling.style.display = \'block\'; this.parentNode.parentNode.nextElementSibling.style.height = \'auto\'; this.parentNode.style.display = \'none\';">read&nbsp;more&nbsp;&rarr;</a></span>';
    });

</script>

</body>
</html>
